{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from nose.tools import *\n",
    "from scipy.stats import normaltest,median_absolute_deviation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,GridSearchCV,cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer,precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA, KernelPCA,IncrementalPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LinDA\n",
    "from sklearn.manifold import Isomap\n",
    "from functools import reduce\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectKBest,chi2,mutual_info_classif,mutual_info_regression,SelectPercentile\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanisms of Action Prediction Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared link on google drive (shared to iordan93@)\n",
    "https://drive.google.com/drive/folders/17pTOVLpfSbLpPC24ggleNfIKi2sLOg3Y?usp=sharing\n",
    "\n",
    "GitHub (without the feature csv file as it exceeds 100 MB)\n",
    "https://github.com/Ynche/MoA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "Essentially, MoA is  an evaluation of a drug performance. After taking of a drug (or taking a placebo) gene expressions and cell features are measured: 872 features in total. Correspondingly, the target is the protein trigger, denoted by 1 (trigger) and 0 (no trigger). The target are 206 proteins which are measured separately. Several targets might be triggered which denotes the task as multi-label. \n",
    "Two problems constitue the main challenge - first, sparsity of data (imbalanced categories) where most of the target columns have less than 1% positive records and second, feature abundance. Feature selection is impeded by lack of linear correlation between features and mainly by problem one - imbalanced categories.\n",
    "Due to lack of computational capacities 6 targets out of 206 are selected (from left tail, median and right tail). Five models are tested - Logistic, Logistic with over and under sampling, Linear SVM with mutual_info_classif feature selection, Random forest, Logistic with PCA. Neither of the models proves to be valuable in predicting protein trigger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "#### 1. Data Overview\n",
    "   1.1 Feature Attributes.\n",
    "   \n",
    "   1.2 Targets.\n",
    "   \n",
    "   1.3 Project Challenges.\n",
    "   \n",
    "   1.4 Data Preprocessing.\n",
    "   \n",
    "#### 2. Methodology\n",
    "   2.0 Target and Feature Preprocessing.\n",
    "   \n",
    "   2.1 Target Selection: Simplified procedure in the context of lack of computational capacities.\n",
    "   \n",
    "   2.2 Feature Engineering: Dummy Variables for Categorical Data.\n",
    "   \n",
    "   3.0 Models. \n",
    "   \n",
    "   3.1 Logistic Regression. \n",
    "   \n",
    "   3.2 Linear SVM with Feature Selection.\n",
    "   \n",
    "   3.3 Random Forest.\n",
    "   \n",
    "   3.4 Logistic Regression with Under and Over Sampling.\n",
    "   \n",
    "   3.5 Models Performace.\n",
    "\n",
    "#### 3. Bibliography\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Data Overview\n",
    "\n",
    "  Mechanism of Action describes the process by which a molecule (a drug in this case), functions to produce a pharmacological effect. A drugâ€™s mechanism of action may refer to its effects on a biological readout such as cell growth, or its interaction and modulation of its direct biomolecular target, for example a protein or nucleic acid. \n",
    "  Data in current study is collected through a cell-based assay designed to capture gene expression and cell viability levels. An assay is an investigational tool used in biology and chemistry for the detection or measurement of a target molecule's presence or functional activity. Based on the patterns in the data, the task is to predict a drug's mechanism of action (MoA). An important point is that the competition is a multi-label competition, not multi-class, meaning that some rows can be associated with multiple targets.\n",
    "   \n",
    "   The measurement of gene expression is based on the L1000 assay. Reference on how it works:\n",
    "https://clue.io/connectopedia/what_is_l1000\n",
    "   \n",
    "   The measurement of cell viability is based on the PRISM assay. Reference on how it works:\n",
    "https://www.luminexcorp.com/blog/prism-a-novel-bead-based-biological-barcode-assay/\n",
    "   \n",
    "   #### 1.1Feature Attributes:\n",
    "   \n",
    "   1. 772 gene expression features, each denoted by \"g-\". Each gene feature represents the expression of one particular gene. Therefore, there are 772 individual genes being monitored. (Float in the range -10 to 10)\n",
    "   2. 100 cell viability features, each denoted by \"c-\". Each cell feature represents the viability of one particular cell line. (Float in the range -10 to 10)\n",
    "   3. In addition to the data collected from the assay, there are three columns explaining the experiment type, dosing, and measurement time.\n",
    "   - Treatment/Control - The cp_type column indicates whether the experiment is a treatment and contains drug or control (contains no drug). The control group is 8% from data. (trt_cp - treatment, ctl_vehicle - control)\n",
    "   - Dosage - The cp_dose column indicates the dose level used in the experiment. Generally, a higher dose will have a stronger effect. (D1 - small dose, D2 - high dose)\n",
    "   - Timing - The cp_time column indicates the amount of time elapsed between adding the drug and when the measurement was taken. For example, some drugs will have an irreversible effect that can still be seen 72 hours after dosing. Other drugs will have lost all effect by that point and may be indistinguishable from controls. (Integer in the range 24 to 72 hours)\n",
    "   \n",
    "   Number of signatures: 23814\n",
    "   Each signature in the dataset is made out of 2 replicates (identical experiments with the same drug) that were collapsed into one vector of values.\n",
    "   \n",
    "   #### 1.2 Targets:\n",
    "   \n",
    "   1. 206 target attributes that represent protein measurement represented as binary data (0 and 1). The target can be interpreted either as a probability of an event (0% or 100%) or two categories. Data is highly unbalanced. The targets that have 238 or less possitive records are 184, meaning that for these 184 columns, the ratio ones to zeroes is less than 1 to 99. \n",
    "   \n",
    "   #### 1.3 Project Challenges:\n",
    "   \n",
    "   There are two significant challenges that the project imposes:\n",
    "\n",
    "   1. Imbalanced target.\n",
    "   The positive category is highly underrepresented. Some models are not robust to unbalanced categories. Possible correction is combination of under and over sampling  with the creation of synthethic observations. Logistic model is tested with the under and over sampling strategy.\n",
    "   \n",
    "   2. High dimensionality of features. \n",
    "   There are 875 features with no linear correlation among them. Although there are 23814 observations, the target is highly imbalanced which reduces the informational gain and thus, the feature selection process. \n",
    "   \n",
    "   #### 1.4 Data Preprocessing\n",
    "   \n",
    "   The gene expression features and cell viability features are normalized using quantile normalization. In the context of measurement of gene expression, the quantile normalization is used to remove the effect of different light bulbs intensity used for different experiments. The new values have the same distribution and the original ranking order of the observations is preserved. The outliers have been normalized using a robust z-score (x-median)/(median absolute deviation * 1.4826). The data is clipped to have min of -10 and max 10.\n",
    "   \n",
    "   https://www.youtube.com/watch?v=ecjN6Xpv6SE\n",
    "   \n",
    "   The treatment,dosage and timing are converted to dummy variables. The baseline groups are excluded as follows: 'cp_type_ctl_vehicle', 'cp_time_24','cp_dose_D1'.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 875 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cp_type  cp_time cp_dose     g-0     g-1     g-2     g-3     g-4  \\\n",
       "sig_id                                                                          \n",
       "id_000644bb2  trt_cp       24      D1  1.0620  0.5577 -0.2479 -0.6208 -0.1944   \n",
       "id_000779bfc  trt_cp       72      D1  0.0743  0.4087  0.2991  0.0604  1.0190   \n",
       "id_000a6266a  trt_cp       48      D1  0.6280  0.5817  1.5540 -0.0764 -0.0323   \n",
       "id_0015fd391  trt_cp       48      D1 -0.5138 -0.2491 -0.2656  0.5288  4.0620   \n",
       "id_001626bd3  trt_cp       72      D2 -0.3254 -0.4009  0.9700  0.6919  1.4180   \n",
       "\n",
       "                 g-5     g-6  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "sig_id                        ...                                           \n",
       "id_000644bb2 -1.0120 -1.0220  ...  0.2862  0.2584  0.8076  0.5523 -0.1912   \n",
       "id_000779bfc  0.5207  0.2341  ... -0.4265  0.7543  0.4708  0.0230  0.2957   \n",
       "id_000a6266a  1.2390  0.1715  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240   \n",
       "id_0015fd391 -0.8095 -1.9590  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632   \n",
       "id_001626bd3 -0.8244 -0.2800  ...  0.0042  0.0048  0.6670  1.0690  0.5523   \n",
       "\n",
       "                c-95    c-96    c-97    c-98    c-99  \n",
       "sig_id                                                \n",
       "id_000644bb2  0.6584 -0.3981  0.2139  0.3801  0.4176  \n",
       "id_000779bfc  0.4899  0.1522  0.1241  0.6077  0.7371  \n",
       "id_000a6266a -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "id_0015fd391 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "id_001626bd3 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 875 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pd.read_csv(\"train_features.csv/train_features.csv\",sep=',',index_col=[0])\n",
    "train_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "sig_id                                                              \n",
       "id_000644bb2                            0                       0   \n",
       "id_000779bfc                            0                       0   \n",
       "id_000a6266a                            0                       0   \n",
       "id_0015fd391                            0                       0   \n",
       "id_001626bd3                            0                       0   \n",
       "\n",
       "              acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "sig_id                                                         \n",
       "id_000644bb2               0                               0   \n",
       "id_000779bfc               0                               0   \n",
       "id_000a6266a               0                               0   \n",
       "id_0015fd391               0                               0   \n",
       "id_001626bd3               0                               0   \n",
       "\n",
       "              acetylcholine_receptor_antagonist  \\\n",
       "sig_id                                            \n",
       "id_000644bb2                                  0   \n",
       "id_000779bfc                                  0   \n",
       "id_000a6266a                                  0   \n",
       "id_0015fd391                                  0   \n",
       "id_001626bd3                                  0   \n",
       "\n",
       "              acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "sig_id                                                                     \n",
       "id_000644bb2                               0                           0   \n",
       "id_000779bfc                               0                           0   \n",
       "id_000a6266a                               0                           0   \n",
       "id_0015fd391                               0                           0   \n",
       "id_001626bd3                               0                           0   \n",
       "\n",
       "              adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "sig_id                                                                    \n",
       "id_000644bb2                              0                           0   \n",
       "id_000779bfc                              0                           0   \n",
       "id_000a6266a                              0                           0   \n",
       "id_0015fd391                              0                           0   \n",
       "id_001626bd3                              0                           0   \n",
       "\n",
       "              adrenergic_receptor_agonist  ...  \\\n",
       "sig_id                                     ...   \n",
       "id_000644bb2                            0  ...   \n",
       "id_000779bfc                            0  ...   \n",
       "id_000a6266a                            0  ...   \n",
       "id_0015fd391                            0  ...   \n",
       "id_001626bd3                            0  ...   \n",
       "\n",
       "              tropomyosin_receptor_kinase_inhibitor  trpv_agonist  \\\n",
       "sig_id                                                              \n",
       "id_000644bb2                                      0             0   \n",
       "id_000779bfc                                      0             0   \n",
       "id_000a6266a                                      0             0   \n",
       "id_0015fd391                                      0             0   \n",
       "id_001626bd3                                      0             0   \n",
       "\n",
       "              trpv_antagonist  tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "sig_id                                                                        \n",
       "id_000644bb2                0                  0                          0   \n",
       "id_000779bfc                0                  0                          0   \n",
       "id_000a6266a                0                  0                          0   \n",
       "id_0015fd391                0                  0                          0   \n",
       "id_001626bd3                0                  0                          0   \n",
       "\n",
       "              ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  \\\n",
       "sig_id                                                                 \n",
       "id_000644bb2                                      0                0   \n",
       "id_000779bfc                                      0                0   \n",
       "id_000a6266a                                      0                0   \n",
       "id_0015fd391                                      0                0   \n",
       "id_001626bd3                                      0                0   \n",
       "\n",
       "              vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "sig_id                                                              \n",
       "id_000644bb2          0                           0              0  \n",
       "id_000779bfc          0                           0              0  \n",
       "id_000a6266a          0                           0              0  \n",
       "id_0015fd391          0                           0              0  \n",
       "id_001626bd3          0                           0              0  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets = pd.read_csv(\"train_targets_scored.csv/train_targets_scored.csv\",sep=',',index_col=[0])\n",
    "train_targets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train features: (23814, 875)\n",
      "Shape of train targets: (23814, 206)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train features:\",train_features.shape)\n",
    "print(\"Shape of train targets:\",train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_time</th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.020156</td>\n",
       "      <td>0.248366</td>\n",
       "      <td>-0.095684</td>\n",
       "      <td>0.152253</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>0.057347</td>\n",
       "      <td>-0.138836</td>\n",
       "      <td>0.035961</td>\n",
       "      <td>-0.202651</td>\n",
       "      <td>-0.190083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.469244</td>\n",
       "      <td>-0.461411</td>\n",
       "      <td>-0.513256</td>\n",
       "      <td>-0.500142</td>\n",
       "      <td>-0.507093</td>\n",
       "      <td>-0.353726</td>\n",
       "      <td>-0.463485</td>\n",
       "      <td>-0.378241</td>\n",
       "      <td>-0.470252</td>\n",
       "      <td>-0.301505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.402807</td>\n",
       "      <td>1.393399</td>\n",
       "      <td>0.812363</td>\n",
       "      <td>1.035731</td>\n",
       "      <td>0.950012</td>\n",
       "      <td>1.032091</td>\n",
       "      <td>1.179388</td>\n",
       "      <td>0.882395</td>\n",
       "      <td>1.125494</td>\n",
       "      <td>1.749885</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000488</td>\n",
       "      <td>2.042475</td>\n",
       "      <td>2.001714</td>\n",
       "      <td>2.107105</td>\n",
       "      <td>2.159589</td>\n",
       "      <td>1.629291</td>\n",
       "      <td>2.059725</td>\n",
       "      <td>1.703615</td>\n",
       "      <td>1.834828</td>\n",
       "      <td>1.407918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>-5.513000</td>\n",
       "      <td>-5.737000</td>\n",
       "      <td>-9.104000</td>\n",
       "      <td>-5.998000</td>\n",
       "      <td>-6.369000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>-0.473075</td>\n",
       "      <td>-0.562200</td>\n",
       "      <td>-0.437750</td>\n",
       "      <td>-0.429575</td>\n",
       "      <td>-0.470925</td>\n",
       "      <td>-0.602225</td>\n",
       "      <td>-0.493900</td>\n",
       "      <td>-0.525175</td>\n",
       "      <td>-0.511675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.566175</td>\n",
       "      <td>-0.565975</td>\n",
       "      <td>-0.589975</td>\n",
       "      <td>-0.568700</td>\n",
       "      <td>-0.563775</td>\n",
       "      <td>-0.567975</td>\n",
       "      <td>-0.552575</td>\n",
       "      <td>-0.561000</td>\n",
       "      <td>-0.592600</td>\n",
       "      <td>-0.562900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>-0.046600</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>-0.026900</td>\n",
       "      <td>-0.015650</td>\n",
       "      <td>-0.000650</td>\n",
       "      <td>-0.017900</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009900</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>-0.009100</td>\n",
       "      <td>-0.013750</td>\n",
       "      <td>-0.003300</td>\n",
       "      <td>-0.010250</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>-0.006800</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>-0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.403075</td>\n",
       "      <td>0.663925</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.465375</td>\n",
       "      <td>0.510425</td>\n",
       "      <td>0.528725</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.549225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457750</td>\n",
       "      <td>0.461500</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.452900</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.444750</td>\n",
       "      <td>0.465225</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>0.461275</td>\n",
       "      <td>0.438650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.039000</td>\n",
       "      <td>8.257000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.282000</td>\n",
       "      <td>7.333000</td>\n",
       "      <td>5.473000</td>\n",
       "      <td>8.887000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.069000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>3.927000</td>\n",
       "      <td>3.596000</td>\n",
       "      <td>3.747000</td>\n",
       "      <td>2.814000</td>\n",
       "      <td>3.505000</td>\n",
       "      <td>2.924000</td>\n",
       "      <td>3.111000</td>\n",
       "      <td>3.805000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 873 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cp_time           g-0           g-1           g-2           g-3  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean      48.020156      0.248366     -0.095684      0.152253      0.081971   \n",
       "std       19.402807      1.393399      0.812363      1.035731      0.950012   \n",
       "min       24.000000     -5.513000     -5.737000     -9.104000     -5.998000   \n",
       "25%       24.000000     -0.473075     -0.562200     -0.437750     -0.429575   \n",
       "50%       48.000000     -0.008850     -0.046600      0.075200      0.008050   \n",
       "75%       72.000000      0.525700      0.403075      0.663925      0.463400   \n",
       "max       72.000000     10.000000      5.039000      8.257000     10.000000   \n",
       "\n",
       "                g-4           g-5           g-6           g-7           g-8  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean       0.057347     -0.138836      0.035961     -0.202651     -0.190083   \n",
       "std        1.032091      1.179388      0.882395      1.125494      1.749885   \n",
       "min       -6.369000    -10.000000    -10.000000    -10.000000    -10.000000   \n",
       "25%       -0.470925     -0.602225     -0.493900     -0.525175     -0.511675   \n",
       "50%       -0.026900     -0.015650     -0.000650     -0.017900      0.010000   \n",
       "75%        0.465375      0.510425      0.528725      0.411900      0.549225   \n",
       "max       10.000000      7.282000      7.333000      5.473000      8.887000   \n",
       "\n",
       "       ...          c-90          c-91          c-92          c-93  \\\n",
       "count  ...  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean   ...     -0.469244     -0.461411     -0.513256     -0.500142   \n",
       "std    ...      2.000488      2.042475      2.001714      2.107105   \n",
       "min    ...    -10.000000    -10.000000    -10.000000    -10.000000   \n",
       "25%    ...     -0.566175     -0.565975     -0.589975     -0.568700   \n",
       "50%    ...     -0.009900      0.003250     -0.009100     -0.013750   \n",
       "75%    ...      0.457750      0.461500      0.445675      0.452900   \n",
       "max    ...      4.069000      3.960000      3.927000      3.596000   \n",
       "\n",
       "               c-94          c-95          c-96          c-97          c-98  \\\n",
       "count  23814.000000  23814.000000  23814.000000  23814.000000  23814.000000   \n",
       "mean      -0.507093     -0.353726     -0.463485     -0.378241     -0.470252   \n",
       "std        2.159589      1.629291      2.059725      1.703615      1.834828   \n",
       "min      -10.000000    -10.000000    -10.000000    -10.000000    -10.000000   \n",
       "25%       -0.563775     -0.567975     -0.552575     -0.561000     -0.592600   \n",
       "50%       -0.003300     -0.010250     -0.001250     -0.006800      0.014000   \n",
       "75%        0.470900      0.444750      0.465225      0.446400      0.461275   \n",
       "max        3.747000      2.814000      3.505000      2.924000      3.111000   \n",
       "\n",
       "               c-99  \n",
       "count  23814.000000  \n",
       "mean      -0.301505  \n",
       "std        1.407918  \n",
       "min      -10.000000  \n",
       "25%       -0.562900  \n",
       "50%       -0.019500  \n",
       "75%        0.438650  \n",
       "max        3.805000  \n",
       "\n",
       "[8 rows x 873 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>23814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.011338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.001260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026709</td>\n",
       "      <td>0.027483</td>\n",
       "      <td>0.031731</td>\n",
       "      <td>0.088967</td>\n",
       "      <td>0.111716</td>\n",
       "      <td>0.055283</td>\n",
       "      <td>0.047566</td>\n",
       "      <td>0.063365</td>\n",
       "      <td>0.022443</td>\n",
       "      <td>0.105876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015871</td>\n",
       "      <td>0.032384</td>\n",
       "      <td>0.044851</td>\n",
       "      <td>0.114429</td>\n",
       "      <td>0.055283</td>\n",
       "      <td>0.015871</td>\n",
       "      <td>0.084190</td>\n",
       "      <td>0.033025</td>\n",
       "      <td>0.040436</td>\n",
       "      <td>0.035472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "count                 23814.000000            23814.000000    23814.000000   \n",
       "mean                      0.000714                0.000756        0.001008   \n",
       "std                       0.026709                0.027483        0.031731   \n",
       "min                       0.000000                0.000000        0.000000   \n",
       "25%                       0.000000                0.000000        0.000000   \n",
       "50%                       0.000000                0.000000        0.000000   \n",
       "75%                       0.000000                0.000000        0.000000   \n",
       "max                       1.000000                1.000000        1.000000   \n",
       "\n",
       "       acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "count                    23814.000000                       23814.000000   \n",
       "mean                         0.007979                           0.012640   \n",
       "std                          0.088967                           0.111716   \n",
       "min                          0.000000                           0.000000   \n",
       "25%                          0.000000                           0.000000   \n",
       "50%                          0.000000                           0.000000   \n",
       "75%                          0.000000                           0.000000   \n",
       "max                          1.000000                           1.000000   \n",
       "\n",
       "       acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "count                    23814.000000                23814.000000   \n",
       "mean                         0.003065                    0.002268   \n",
       "std                          0.055283                    0.047566   \n",
       "min                          0.000000                    0.000000   \n",
       "25%                          0.000000                    0.000000   \n",
       "50%                          0.000000                    0.000000   \n",
       "75%                          0.000000                    0.000000   \n",
       "max                          1.000000                    1.000000   \n",
       "\n",
       "       adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "count                   23814.000000                23814.000000   \n",
       "mean                        0.004031                    0.000504   \n",
       "std                         0.063365                    0.022443   \n",
       "min                         0.000000                    0.000000   \n",
       "25%                         0.000000                    0.000000   \n",
       "50%                         0.000000                    0.000000   \n",
       "75%                         0.000000                    0.000000   \n",
       "max                         1.000000                    1.000000   \n",
       "\n",
       "       adrenergic_receptor_agonist  ...  \\\n",
       "count                 23814.000000  ...   \n",
       "mean                      0.011338  ...   \n",
       "std                       0.105876  ...   \n",
       "min                       0.000000  ...   \n",
       "25%                       0.000000  ...   \n",
       "50%                       0.000000  ...   \n",
       "75%                       0.000000  ...   \n",
       "max                       1.000000  ...   \n",
       "\n",
       "       tropomyosin_receptor_kinase_inhibitor  trpv_agonist  trpv_antagonist  \\\n",
       "count                           23814.000000  23814.000000     23814.000000   \n",
       "mean                                0.000252      0.001050         0.002016   \n",
       "std                                 0.015871      0.032384         0.044851   \n",
       "min                                 0.000000      0.000000         0.000000   \n",
       "25%                                 0.000000      0.000000         0.000000   \n",
       "50%                                 0.000000      0.000000         0.000000   \n",
       "75%                                 0.000000      0.000000         0.000000   \n",
       "max                                 1.000000      1.000000         1.000000   \n",
       "\n",
       "       tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "count       23814.000000               23814.000000   \n",
       "mean            0.013270                   0.003065   \n",
       "std             0.114429                   0.055283   \n",
       "min             0.000000                   0.000000   \n",
       "25%             0.000000                   0.000000   \n",
       "50%             0.000000                   0.000000   \n",
       "75%             0.000000                   0.000000   \n",
       "max             1.000000                   1.000000   \n",
       "\n",
       "       ubiquitin_specific_protease_inhibitor  vegfr_inhibitor     vitamin_b  \\\n",
       "count                           23814.000000     23814.000000  23814.000000   \n",
       "mean                                0.000252         0.007139      0.001092   \n",
       "std                                 0.015871         0.084190      0.033025   \n",
       "min                                 0.000000         0.000000      0.000000   \n",
       "25%                                 0.000000         0.000000      0.000000   \n",
       "50%                                 0.000000         0.000000      0.000000   \n",
       "75%                                 0.000000         0.000000      0.000000   \n",
       "max                                 1.000000         1.000000      1.000000   \n",
       "\n",
       "       vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "count                23814.000000   23814.000000  \n",
       "mean                     0.001638       0.001260  \n",
       "std                      0.040436       0.035472  \n",
       "min                      0.000000       0.000000  \n",
       "25%                      0.000000       0.000000  \n",
       "50%                      0.000000       0.000000  \n",
       "75%                      0.000000       0.000000  \n",
       "max                      1.000000       1.000000  \n",
       "\n",
       "[8 rows x 206 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfoming a check for missing values. There are no missing values for both features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing train features: 0\n",
      "Missing train targets: 0\n"
     ]
    }
   ],
   "source": [
    "train_miss_features=train_features.isnull().sum().sum()\n",
    "train_miss_targets=train_targets.isnull().sum().sum()\n",
    "print(\"Missing train features:\",train_miss_features)\n",
    "print(\"Missing train targets:\",train_miss_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 872 float features in the range of -10 to 10 and 3 categorical features. We check which are the unique categories for the three categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories for dose: ['D1' 'D2']\n",
      "Unique categories for treatment: ['trt_cp' 'ctl_vehicle']\n",
      "Unique categories for drug timing: [24 72 48]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique categories for dose:\",train_features.cp_dose.unique())\n",
    "print(\"Unique categories for treatment:\",train_features.cp_type.unique())\n",
    "print(\"Unique categories for drug timing:\",train_features.cp_time.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity we check what is the percentage of the control group taking the placebo ~ 8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trt_cp         21948\n",
       "ctl_vehicle     1866\n",
       "Name: cp_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.cp_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_ones_columns(df,percent_ones):\n",
    "    \"\"\"Counts the number of features with less or equal percentage of Positive records. Used for dummy/binary data\"\"\"\n",
    "    ones= np.count_nonzero(df==1, axis=0)\n",
    "    df_ones = pd.DataFrame({'Count_ones':ones/df.shape[0]})\n",
    "    sum_ones= (df_ones<=percent_ones).sum()\n",
    "    return f'Number of columns that have equal or less than {percent_ones*100}% Positive records:{repr(sum_ones)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of columns that have equal or less than 1.0% Positive records:Count_ones    184\\ndtype: int64'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_ones_columns(train_targets,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_binary_data(df,zero_or_one,bins,x_label,y_label,xlim_min=None,xlim_max=None):\n",
    "    \"\"\"Histogram of distribution of ones or zeros for dummy/binary data.\"\"\"\n",
    "    np_ones= np.count_nonzero(df==zero_or_one, axis=0)\n",
    "    df_ones = pd.DataFrame({'Count_ones':np_ones})\n",
    "    plt.hist(df_ones['Count_ones'],bins=bins)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlim(xlim_min,xlim_max)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the the target variables are highly unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram_binary_data(train_targets,1,100,'Number of Positives','Number of Targets',xlim_min=None,xlim_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAYZ0lEQVR4nO3de5gldX3n8fcHxEsURTKtO4LjAHEfJV5GMqL7kEXESxCMIAGVzaM8hmSMt+BqnjiaXcU1RgyLRjeuikLErIos3vCKLA6wZne5DzBIkItjRCYMxgvIEzED3/2jquHQ9OV0M3XOaer9ep7zdJ06dao+Xd397d/5VdWvUlVIkvpjh3EHkCSNloVfknrGwi9JPWPhl6SesfBLUs88aNwBhrFixYpavXr1uGNI0rJyySWX/LiqpmbOXxaFf/Xq1Vx88cXjjiFJy0qSH8w2364eSeoZC78k9YyFX5J6xsIvST1j4ZeknrHwS1LPWPglqWcs/JLUMxZ+SeqZZXHl7lKtXv+1WedvPv6QESeRpMlhi1+SesbCL0k9Y+GXpJ6x8EtSz1j4JalnLPyS1DMWfknqGQu/JPVMZ4U/yUOTXJjk8iRXJXlXO3+PJBckuTbJ55I8uKsMkqT76rLFfwdwYFU9HVgDHJTk2cD7gA9U1ROBnwLHdJhBkjRDZ4W/Gr9on+7UPgo4EDijnX8qcFhXGSRJ99VpH3+SHZNsBLYCZwPXAz+rqm3tIjcCu3WZQZJ0b50W/qq6s6rWALsD+wJPnm2x2d6bZF2Si5NcfMstt3QZU5J6ZSRn9VTVz4BzgWcDuySZHhV0d+CmOd5zUlWtraq1U1NTo4gpSb3Q5Vk9U0l2aacfBjwfuBrYABzRLnY08OWuMkiS7qvL8fhXAqcm2ZHmH8zpVfXVJN8FTkvyF8BlwMkdZpAkzdBZ4a+qK4BnzDL/Bpr+fknSGHjlriT1jIVfknrGwi9JPWPhl6SesfBLUs9Y+CWpZyz8ktQzFn5J6hkLvyT1jIVfknrGwi9JPWPhl6SesfBLUs9Y+CWpZyz8ktQzFn5J6hkLvyT1jIVfknrGwi9JPWPhl6SesfBLUs9Y+CWpZyz8ktQzFn5J6pnOCn+SxyfZkOTqJFclObadf1ySHyXZ2D4O7iqDJOm+HtThurcBb6mqS5PsDFyS5Oz2tQ9U1X/tcNuSpDl0VviraguwpZ2+LcnVwG5dbU+SNJwuW/x3S7IaeAZwAbAf8IYkrwIupvlU8NNZ3rMOWAewatWqUcRk9fqvzfna5uMPGUkGSepa5wd3kzwC+Dzwpqq6FfgIsBewhuYTwYmzva+qTqqqtVW1dmpqquuYktQbnRb+JDvRFP1PV9UXAKrq5qq6s6ruAj4O7NtlBknSvXV5Vk+Ak4Grq+r9A/NXDiz2UmBTVxkkSffVZR//fsArgSuTbGznvR04KskaoIDNwGs6zCBJmqHLs3q+A2SWl77e1TYlSQvzyl1J6hkLvyT1zKIKf5JHJdm7qzCSpO4tWPiTnJPkkUkeDVwJfCbJCd1HkyR1YZgW/67thVeHA6dW1Rrgd7qNJUnqyjCF/0FJpoAjga90nEeS1LFhCv97gPOAf6yqC5PsCXy/21iSpK4Mcx7/5qq6+4BuVd2Q5L0dZpIkdWiYFv9/n2Xeh7d3EEnSaMzZ4k+yL/DvgKkkfzLw0iOBnboOJknqxnxdPQ8HVrTLDI6LfBvNgV5J0jI0Z+Gvqg3AhiR/2/brP6Sq7hhhNklSB4bp41+R5ErgWoAkT0/y37qNJUnqyjBn9XwIeDHwJYCqujzJcztNNYu5bovoLRElaXGGafHvUFU/mDHvzi7CSJK6N0yL/4ftGT6VZEfgjcD3uo0lSerKMC3+1wJvBlYBNwPPbudJkpahBVv8VbUVeMUIskiSRmDBwp/k/bPM/jlwcVXNfsRVkjSxhunq2Rl4FvDD9vFM4N8Ar0tyYofZJEkdGObg7l7AAVX1rwBJ/gb4Js2Y/JcDb+kuniRpexumxb8b8LCB5w8DdquqbYBX8krSMjNMi//9wMYk5wABDgBOSPJw4NzuokmSujBviz9JgDOB/Wm6d74JPLeqPlZVt1fVm+d57+OTbEhydZKrkhzbzt81ydlJrm2/Pno7fj+SpAXMW/irqoCvVtWNVfX5qjqjqn445Lq3AW+pqifTnPv/+iR7A+uBc6rqicA57XNJ0ogM08d/YZJ9FrviqtpSVZe207cBV9McLzgUOLVd7FTgsMWuW5K0dMP08f828EdJrgdup+nnr6oa+p9BktXAM4ALgMdW1RaalWxJ8pg53rMOWAewatUqMuzGJEnzGqbw368WeZJHAJ8H3lRVtzaHDRZWVScBJwGsXbu2fnx/QkiS7jbMkA3XQ3NQFnjoYlaeZCeaov/pqvpCO/vmJCvb1v5KYOsiM0uS7ocF+/iTHJLke8CNNF01PwS+PcT7ApwMXF1Vg8M+nAkc3U4fDXx5saElSUs3zMHd9wD7AddU1eOBgxju/P39gFcCBybZ2D4OBo4HXpDkWuAF7XNJ0ogM08e/rapuSbJDklTV2Unes9Cbquo7MOcx2ectKqUkabsZpvD/vL1K9zvAp5JsBe7qNpYkqSvDdPUcBvwSeBNNF8+PgN/tMJMkqUNztviTfKuqXthefAXNfXZPHk0sSVJX5mvxT40shSRpZObr439UksPnenHgvHxJ0jIyb+EHXszsZ+YUYOGXpGVovsL/g6r6g5ElkSSNxHx9/I6LJkkPQPMV/leOLIUkaWTmLPxVtWmUQSRJozHMBVySpAeQOQt/e3N1krxvdHEkSV2b76yelUmeA7wkyWnMONg7fVtFSdLyMl/hfwfNjdB3B94/47UCDuwqlCSpO3MW/qo6AzgjyX+uqnePMJMkqUPD3Hrx3UleAuzfzjq3qr7abSxJUleGufXie4Fjge+2j2PbeZKkZWiYG7EcAqypqrsAkpwKXAa8rctgkqRuDHse/y4D04/qIogkaTSGafG/F7gsyQaaUzr3x9a+JC1bwxzc/WySc4Fn0hT+t1bVP3UdTJLUjWFa/FTVFuDMjrNIkkbAsXokqWcs/JLUM/MW/iQ7JFnS8MxJTkmydfD9SY5L8qMkG9vHwUtZtyRp6eYt/O25+5cnWbWEdX8SOGiW+R+oqjXt4+tLWK8k6X4Y5uDuSuCqJBcCt0/PrKqXzPemqjo/yer7lU6StN0NU/jftZ23+YYkrwIuBt5SVT+dbaEk64B1AKtWrdquNwBevf5r23FtkrS8LHhwt6rOAzYDO7XTFwFLHYv/I8BewBpgC3DiPNs9qarWVtXaqampJW5OkjTTMIO0/RFwBvCxdtZuwJeWsrGqurmq7myPHXwc2Hcp65EkLd0wp3O+HtgPuBWgqq4FHrOUjSVZOfD0pYA3dJekERumj/+OqvpV0vSyJ3kQzR245pXks8ABwIokNwLvBA5IsqZ9/2bgNUuLLUlaqmEK/3lJ3g48LMkLgNcBX1noTVV11CyzT15kPknSdjZM4V8PHANcSdNC/zrwiS5DLYZn6EjS4gwzOudd7c1XLqDpormmqhbs6pEkTaYFC3+SQ4CPAtfTDMu8R5LXVNU3ug4nSdr+hunqORF4blVdB5BkL+BrgIVfkpahYU7n3Dpd9Fs3AFs7yiNJ6ticLf4kh7eTVyX5OnA6TR//kTRX70qSlqH5unp+d2D6ZuA57fQtwKM7SyRJ6tSchb+qXj3KIJKk0RjmrJ49gDcCqweXX2hYZknSZBrmrJ4v0Vxx+xXgrm7jSJK6Nkzh/2VVfajzJJKkkRim8H8wyTuBbwF3TM+sqqWOyS9JGqNhCv9TgVcCB3JPV0+1zyVJy8wwhf+lwJ5V9auuw0yyuQaD23z8IWNdlyQt1jBX7l4O7NJ1EEnSaAzT4n8s8A9JLuLeffyezilJy9Awhf+dnaeQJI3MMOPxnzeKIJKk0Rjmyt3buOceuw8GdgJur6pHdhlMktSNYVr8Ow8+T3IYsG9niSRJnRqmj/9equpLSdZ3EeaBxHsBS5pUw3T1HD7wdAdgLfd0/UiSlplhWvyD4/JvAzYDh3aSRpLUuWH6+Jc0Ln+SU4AX09y68SntvF2Bz9EM8bwZeFlV/XQp65ckLc18t158xzzvq6p69wLr/iTwN8CnBuatB86pquPb4wTrgbcOmVWStB3MN2TD7bM8AI5hiGJdVecDP5kx+1Dg1Hb6VOCwxYSVJN1/89168cTp6SQ7A8cCrwZOA06c630LeGxVbWnXvyXJY+ZaMMk6YB3AqlWryBI3KEm6t3kHaUuya5K/AK6g+SexT1W9taq2dh2sqk6qqrVVtXZqaqrrzUlSb8xZ+JOcAFwE3AY8taqO2w4HYm9OsrJd/0qg838gkqR7m6/F/xbgccB/Am5Kcmv7uC3JrUvc3pnA0e300cCXl7geSdISzdfHP8xY/XNK8lngAGBFkhtpRvk8Hjg9yTHAPwJH3p9tSJIWb9FDNgyrqo6a46XndbVNSdLC7lerXpK0/HTW4u8LB2OTtNzY4peknrHwS1LPWPglqWcs/JLUMxZ+SeoZC78k9YyFX5J6xsIvST1j4ZeknrHwS1LPWPglqWcs/JLUMxZ+SeoZC78k9YyFX5J6xsIvST1j4ZeknrHwS1LPeOvFZW6uWz9uPv6QESeRtFzY4peknrHwS1LPjKWrJ8lm4DbgTmBbVa0dRw5J6qNx9vE/t6p+PMbtS1Iv2dUjST0zrhZ/Ad9KUsDHquqkmQskWQesA1i1ahUZccDlbq6zfcAzfqS+G1eLf7+q2gd4EfD6JPvPXKCqTqqqtVW1dmpqavQJJekBaiyFv6puar9uBb4I7DuOHJLURyMv/EkenmTn6WnghcCmUeeQpL4aRx//Y4EvJpne/meq6ptjyCFJvTTywl9VNwBPH/V2JUkNT+eUpJ5xkLZlYr7TMyVpMWzxS1LPWPglqWcs/JLUMxZ+SeoZC78k9Yxn9UwQz9zR9rKU3yUH7+sPW/yS1DMWfknqGQu/JPWMhV+SesbCL0k9Y+GXpJ7xdM4e2p6njS7lFMC5tr89Tyec5HsOb8/vvy+nAI/id2ZUJuF7scUvST1j4ZeknrHwS1LPWPglqWcs/JLUM57Vo4mxHAcWm4QzNEZh3GeCbU99+D1b6Hu0xS9JPWPhl6SesfBLUs+MpfAnOSjJNUmuS7J+HBkkqa9GXviT7Ah8GHgRsDdwVJK9R51DkvpqHC3+fYHrquqGqvoVcBpw6BhySFIvpapGu8HkCOCgqvrD9vkrgWdV1RtmLLcOWNc+fQqwaaRBh7MC+PG4Q8xhUrNNai6Y3GyTmgsmN9uk5oLRZntCVU3NnDmO8/gzy7z7/PepqpOAkwCSXFxVa7sOtliTmgsmN9uk5oLJzTapuWBys01qLpiMbOPo6rkRePzA892Bm8aQQ5J6aRyF/yLgiUn2SPJg4BXAmWPIIUm9NPKunqraluQNwFnAjsApVXXVAm87qftkSzKpuWBys01qLpjcbJOaCyY326TmggnINvKDu5Kk8fLKXUnqGQu/JPXMRBf+SRvaIcnmJFcm2Zjk4nberknOTnJt+/XRI8pySpKtSTYNzJs1SxofavfjFUn2GXGu45L8qN1vG5McPPDa29pc1yT5nQ5zPT7JhiRXJ7kqybHt/EnYZ3NlG+t+S/LQJBcmubzN9a52/h5JLmj32efakzRI8pD2+XXt66u7yLVAtk8m+f7APlvTzh/Zz7Pd3o5JLkvy1fb52PfZvVTVRD5oDvxeD+wJPBi4HNh7zJk2AytmzPsrYH07vR5434iy7A/sA2xaKAtwMPANmmsong1cMOJcxwF/Osuye7c/14cAe7Q/7x07yrUS2Ked3hn4Xrv9Sdhnc2Ub635rv/dHtNM7ARe0++J04BXt/I8Cr22nXwd8tJ1+BfC5DvfZXNk+CRwxy/Ij+3m223sz8Bngq+3zse+zwcckt/iXy9AOhwKnttOnAoeNYqNVdT7wkyGzHAp8qhr/D9glycoR5prLocBpVXVHVX0fuI7m595Fri1VdWk7fRtwNbAbk7HP5so2l5Hst/Z7/0X7dKf2UcCBwBnt/Jn7bHpfngE8L8lsF2x2mW0uI/t5JtkdOAT4RPs8TMA+GzTJhX834IcDz29k/j+GUSjgW0kuSTOkBMBjq2oLNH/AwGPGlm7uLJOwL9/QfsQ+ZaA7bCy52o/Tz6BpJU7UPpuRDca839oui43AVuBsmk8XP6uqbbNs++5c7es/B369i1yzZauq6X32nnaffSDJQ2ZmmyX39vbXwJ8Bd7XPf50J2WfTJrnwDzW0w4jtV1X70Iws+vok+485z7DGvS8/AuwFrAG2ACe280eeK8kjgM8Db6qqW+dbdJZ5o8429v1WVXdW1RqaK+z3BZ48z7ZHus9mZkvyFOBtwJOAZwK7Am8dZbYkLwa2VtUlg7Pn2fZY/jYnufBP3NAOVXVT+3Ur8EWaP4Sbpz8ytl+3ji/hnFnGui+r6ub2j/Qu4OPc0y0x0lxJdqIprJ+uqi+0sydin82WbVL2W5vlZ8C5NP3juySZvvhzcNt352pffxTDd/ttj2wHtd1mVVV3AH/L6PfZfsBLkmym6Z4+kOYTwETts0ku/BM1tEOShyfZeXoaeCHNiKFnAke3ix0NfHk8CWGeLGcCr2rPbHg28PPp7o1RmNGX+lLuGWn1TOAV7ZkNewBPBC7sKEOAk4Grq+r9Ay+NfZ/NlW3c+y3JVJJd2umHAc+nOf6wATiiXWzmPpvel0cA3672qOWIsv3DwD/x0PSjD+6zzn+eVfW2qtq9qlbT1KxvV9XvMwH7bGbQiX3QHIn/Hk2/4p+POcueNGdSXA5cNZ2Hpj/uHODa9uuuI8rzWZqP//9K02o4Zq4sNB8nP9zuxyuBtSPO9Xftdq+g+UVfObD8n7e5rgFe1GGu36b5CH0FsLF9HDwh+2yubGPdb8DTgMva7W8C3jHwt3AhzUHl/wk8pJ3/0Pb5de3re3a4z+bK9u12n20C/gf3nPkzsp/nQMYDuOesnrHvs8GHQzZIUs9MclePJKkDFn5J6hkLvyT1jIVfknrGwi9JPWPh19gkqSQnDjz/0yTHbad1fzLJEQsveb+3c2SaUTU3zJi/Osm/tCNEfjfJR5Ms+u8tydeT7NI+Xjcw/3FJzpjvvdJcLPwapzuAw5OsGHeQQUl2XMTixwCvq6rnzvLa9dUMKfA0mhE1Fz2AX1UdXM2VqbvQjOQ4Pf+mqur8H5semCz8GqdtNPcf/Y8zX5jZYk/yi/brAUnOS3J6ku8lOT7J76cZm/3KJHsNrOb5Sf53u9yL2/fvmOSEJBe1A3m9ZmC9G5J8huYCn5l5jmrXvynJ+9p576C5+OqjSU6Y65usZvCt/wP8Rnvl6Anteq5M8vJ2XSuTnN9+QtiU5N+38ze3/xiPB/ZqXz+h/USxqV3mgiS/OZD13CS/1V5tfkr7vV6W5ND29d9s99fGdh88ceEflR5IRn6zdWmGDwNXJPmrRbzn6TSDhf0EuAH4RFXtm+YGJm8E3tQutxp4Ds1AZxuS/AbwKprL9Z+ZZuTGv0/yrXb5fYGnVDPU8d2SPA54H/BbwE9pRmg9rKr+S5IDacbMv3iusEl+DXge8A7gcJpB154OrAAuSnI+8B+As6rqPe0njl+bsZr1bbbpG4usHnjtNOBlwDvbIQseV1WXJPlLmiEA/qAd3uDCJP8L+GPgg1X16TTDoSzmE44eAGzxa6yqGYXyU8CfLOJtF1UzGNcdNJfgTxfuK2mK/bTTq+quqrqW5h/Ek2jGWHpVmuF8L6AZsmG6xXvhzKLfeiZwblXd0rbeP01zw5mF7NVu5++Br1XVN2g+IXy2msHXbgbOa9d/EfDq9hjHU6sZl39YpwNHttMvoxkCgPZ7Xd9mOJdmeIBVwP8F3p7krcATqupfFrEtPQDY4tck+GvgUprRFKdto22YtANuPXjgtTsGpu8aeH4X9/6dnjkeSdGM2fLGqjpr8IUkBwC3z5FvqTfGmO7jX3BdVXV+mmG+DwH+LskJVfWpYTZSVT9K8s9Jnga8HHjNwLZ+r6qumfGWq5Nc0G7rrCR/WFXfHvab0vJni19jV1U/oWm1HjMwezNN1wo0dynaaQmrPjLJDm2//540A5qdBbw2zTDIJPm3aUZbnc8FwHOSrGi7YY6iaakvxfnAy9tjDVM0nxwuTPIEmnHcP04zUufMe8LeRnNbxrmcRnPzj0dV1fQxirOAN7b/OEnyjPbrnsANVfUhmsHfnrbE70XLlIVfk+JEmj7vaR+nKbYXAs9i7tb4fK6hKdDfAP64qn5Jczu87wKXtgdHP8YCn3yrGb73bTRD614OXFpVSx1++4s0I0peTjOS5J9V1T/RjOS4McllwO8BH5yR4Z9pjkdsmuNA8hk0wwCfPjDv3TT/MK9ov9d3t/NfDmxqu4CeRNPVph5xdE5J6hlb/JLUMxZ+SeoZC78k9YyFX5J6xsIvST1j4ZeknrHwS1LP/H9zLy1NlxiHPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram_binary_data(train_targets,1,100,'Number of Positives','Number of Targets',xlim_min=0,xlim_max=435)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histogram_binary_data(train_targets,0,100,'Number of Negatives','Number of Targets',xlim_min=None,xlim_max=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1,   6,   7,  12,  13,  17,  18,  19,  23,  24,  25,  26,  29,\n",
       "         30,  31,  32,  35,  36,  37,  38,  39,  42,  43,  44,  47,  48,\n",
       "         49,  50,  51,  54,  55,  56,  59,  60,  61,  62,  66,  67,  68,\n",
       "         71,  72,  73,  74,  80,  84,  85,  89,  92,  93,  96,  97,  98,\n",
       "        102, 103, 104, 106, 115, 119, 121, 127, 130, 151, 158, 165, 170,\n",
       "        190, 192, 223, 236, 241, 264, 266, 267, 270, 273, 279, 281, 283,\n",
       "        297, 301, 316, 336, 340, 360, 367, 402, 404, 424, 435, 726, 832],\n",
       "       dtype=int32),\n",
       " array([ 2, 16,  4, 11,  2,  1, 13,  4,  2,  5,  8,  3,  1,  6,  4,  1,  1,\n",
       "        12,  6,  1,  1,  4,  1,  1,  1,  7,  1,  1,  1,  3,  2,  2,  1,  3,\n",
       "         3,  2,  1,  2,  1,  1,  3,  5,  2,  2,  1,  1,  2,  1,  1,  3,  1,\n",
       "         1,  1,  1,  1,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones= np.count_nonzero(train_targets==1, axis=0)\n",
    "ones.sort()\n",
    "np.unique(ones,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_grid(rows,cols,bins,x_label,y_label,figsize,feature_list): \n",
    "    \"\"\"Histogram of features with the option to choose number of features to be displayed and in what format: number of rows and \"\"\"\n",
    "    if len(feature_list)!=rows*cols:\n",
    "        raise Exception(\"Feature list length must correspond to plot size\")\n",
    "    fig, axs = plt.subplots(rows, cols,figsize=(figsize[0],figsize[1]))\n",
    "    index = 0\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            axs[row, col].hist(train_features[feature_list[index]],bins=20)\n",
    "            axs[row, col].set_title(feature_list[index])\n",
    "            index = index+1\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "subplot_grid(rows=2,cols=4,bins=20,x_label='Measurement',y_label='Number of Signatures',figsize=(15,4),feature_list=[\"g-320\",\"g-321\",\"g-322\",\"g-323\",\"g-324\",\"g-325\",\"g-326\",\"g-327\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram of the featuers it seems that they are normally distributed. We perform a normality check where the null hypothesis it that he features comes from normal distribution. We can reject the null with confidence 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normality(df,p_value):\n",
    "    features_normal = 0\n",
    "    columns  =0\n",
    "    for column in df:\n",
    "        if df[column].dtype!='O':\n",
    "            columns = columns +1\n",
    "            stat, p = normaltest(df[column])\n",
    "            if p>=p_value:\n",
    "                features_normal = features_normal+1\n",
    "                print(f\"Column {column} comes from normal distribution with p-value {p}\")\n",
    "    print(f\"Number of features where normal distribution cannot be rejected: {features_normal}\")   \n",
    "    print(f\"Number of features where normal distribution can be rejected: {columns-features_normal}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features where normal distribution cannot be rejected: 0\n",
      "Number of features where normal distribution can be rejected: 873\n"
     ]
    }
   ],
   "source": [
    "test_normality(train_features,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to save computational memory we will make a custom correlation half matrix. We choose Spearman since the method is more robust to nonnormality of distribution. To make reading the matrix easier, we set up a threshold for which we want the function to count the number of features above and below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_half_matrix(df,coef_threshold,method):\n",
    "    \"\"\"Correlation half matrix\"\"\"\n",
    "    dct = {'feature1':[],'feature2':[],'corr':[]}\n",
    "    num_correlations = 0\n",
    "    for ind, col1 in  enumerate(df.columns):\n",
    "        for col2 in df.columns[ind+1:]:\n",
    "            corr = df[col1].corr(df[col2], method=method)\n",
    "            dct['feature1'].append(col1)\n",
    "            dct['feature2'].append(col2)\n",
    "            dct['corr'].append(corr)\n",
    "            if corr>=coef_threshold or corr<=-coef_threshold:\n",
    "                num_correlations = num_correlations+1\n",
    "                print(f\"Columns: {col1}, {col2} Correlation coefficient: {corr}\")\n",
    "            del corr    \n",
    "    print(f\"Number of correlations with coefficient greater or equal to [{coef_threshold}]: {num_correlations}\")\n",
    "    print(f\"Number of correlations with coefficient less than [{coef_threshold}]: {len(df.columns)-num_correlations}\")\n",
    "    df = pd.DataFrame(dct)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix= correlation_half_matrix(train_features,0.05)\n",
    "corr_matrix.to_csv(\"corr_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=pd.read_csv(\"corr_matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram, almost all features' correlations are between -0.4 and 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Correlation coefficient')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(corr_matrix.iloc[:,3],bins=50)\n",
    "plt.ylabel('Feature pairs')\n",
    "plt.xlabel('Correlation coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Methodology\n",
    "\n",
    "  A simple to complex approach is applied where each target is modelled independantly from other targets. The underlying assumption is that the targets might be affected differently and if, for example, for one target the best descriptive relationship might be linear, for another it might be exponential or logarithmic. Theoretically, in this case there will be up to 206 different models best describing each target while the rest of the targets are not employed as an input variables.\n",
    "   A dataframe matrix is created where the columns are the 206 targets and each row contains an instance object. The instance represents the best estimated model that the grid search has determined for the respective target and type of model. \n",
    "  \n",
    "   #### 2.0 Target and Feature Preprocessing\n",
    "\n",
    "   #### 2.1 Target Selection: Simplified procedure in the context of lack of computational capacities.\n",
    "Due to limitations of the computational capacities to estimate for 206 targets, a nonrepresentatiove sample of 6 targets is employed. The goal is to build a valid methodology that can be applied to the to the full scope in case we have the computational capacity to do so.The methodology remains unchanged. \n",
    "The samples are: median of the distribution and one median absolute deviation to the right and left of the median. The median estimate is chosen due to its robustness in the context of outliers.  \n",
    "A function is created that uses a grid search with stratified k fold split and returns the best model based on the chosen scoring strategy.\n",
    "\n",
    "   #### 2.2 Feature Engineering: Dummy Variables for Categorical Data.\n",
    "For the three categorical variables we will create dummies. For each category we will drop baseline dummies to avoid collinearity. The dropped dummies will be included in the model intercept as a baseline.   \n",
    "   \n",
    "   #### 3.0 Models. \n",
    "   \n",
    "   #### 3.1 Logistic Regression. \n",
    "   Logistic regression is an elegant mathematical transforamtion of the linear regression to provide the probability of an event. The model in essense is linear as it assumes linearity of independent variables and log odds. Logreg can be used for mixed dummy and continous independent variables. Independent variables should not be linearly correlated.\n",
    "   #### 3.2 Linear SVM with Feature Selection\n",
    "   The Linear SVM chooses a line that best separates classes in the multidimensional space. In order to optimize the model we reduce the number of features. The method is Select Percentile class that uses the function mutual_info_classif. The Select Percentile keeps the top percentile features. mutual_info_classif ranks the importance of features by measuring the dependency between the variables. The function is based on entropy estimation from k-nearest neighbors distances.\n",
    "   #### 3.3 Random Forest\n",
    "   A standard random forest is fitted to the training set with no feature selection.\n",
    "   #### 3.4  Logistic Regression with Under and Over Sampling.\n",
    "   A rule of thumb for linear modeling is that the number of features should not exceed the number of samples. As an example, if we consider the meadian case, we have 39 positives to 23775 negatives(bcr-abl_inhibitor) and for the mean case, the ratio is 81 positives to 23733 negaitives. In case of undersampling with 1:1 ratio and no feature extraction there will be 78 samples in the meadian case and 162 samples in the mean case. Therefore, a preferred approach is to perform oversampling and undersampling combined. Since there is no memory to perform first overampling we perform undersampling first instead. \n",
    "   \n",
    "   #### 3.5 Models Performace.\n",
    "   Models are scored on train and validation test sets using f1 score.\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Target Selection: Simplified procedure in the context of lack of computational capacities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take for measure one median absolute deviation to the left, then we will have a target with just 1 positive observation. We will substitute the observation and instead, for the left tail, we will take a target with 6 positive observations (they are 16 out of 206) and 18 positive observations (they are 13 out of 206)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 81.76699029126213\n",
      "Median: 38.5\n",
      "Standard deviation: 114.88049543219893\n",
      "Median absolute deviation: 37.8063\n",
      "Target with 18 positive observations added: 11-beta-hsd1_inhibitor\n",
      "Target with 6 positive observations added: antiarrhythmic\n",
      "Median added: bcr-abl_inhibitor\n",
      "Median absolute deviation to the right added: glutamate_receptor_agonist\n",
      "Median absolute deviation to the right added: membrane_integrity_inhibitor\n",
      "Median added: vitamin_d_receptor_agonist\n",
      "Shape of reduced target dataframe: (23814, 6)\n"
     ]
    }
   ],
   "source": [
    "array_ones= np.count_nonzero(train_targets==1, axis=0)\n",
    "mean = np.mean(array_ones)\n",
    "med = np.median(array_ones)\n",
    "std = array_ones.std()\n",
    "mad = median_absolute_deviation(array_ones)\n",
    "print('Mean:',mean)\n",
    "print('Median:',med)\n",
    "print('Standard deviation:',std)\n",
    "print(\"Median absolute deviation:\", mad)\n",
    "six = 0\n",
    "eightn = 0\n",
    "train_targets_reduced = pd.DataFrame()\n",
    "for col in train_targets.columns:\n",
    "    if train_targets[col].sum()==np.floor(med) or train_targets[col].sum()==np.ceil(med):\n",
    "        train_targets_reduced[col]=train_targets[col]\n",
    "        print(\"Median added:\",col)\n",
    "    if train_targets[col].sum()==round(med+mad-2):\n",
    "        train_targets_reduced[col]=train_targets[col]\n",
    "        print(\"Median absolute deviation to the right added:\",col)\n",
    "    if train_targets[col].sum()==6 and six ==0:\n",
    "        train_targets_reduced[col]=train_targets[col]\n",
    "        six = 1\n",
    "        print(\"Target with 6 positive observations added:\",col)\n",
    "    if train_targets[col].sum()==18 and eightn ==0:\n",
    "        train_targets_reduced[col]=train_targets[col]\n",
    "        eightn = 1\n",
    "        print(\"Target with 18 positive observations added:\",col)\n",
    "print(\"Shape of reduced target dataframe:\", train_targets_reduced.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_reduced.to_csv(\"train_targets_reduced.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Feature Engineering: Dummy Variables for Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_dummies=pd.get_dummies(train_features, columns=['cp_type','cp_dose','cp_time'])\n",
    "train_features_b_dummies=train_features_dummies.drop(columns=['cp_type_ctl_vehicle', 'cp_time_24','cp_dose_D1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>g-9</th>\n",
       "      <th>...</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "      <th>cp_type_trt_cp</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>1.0620</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>-0.2479</td>\n",
       "      <td>-0.6208</td>\n",
       "      <td>-0.1944</td>\n",
       "      <td>-1.0120</td>\n",
       "      <td>-1.0220</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>0.5548</td>\n",
       "      <td>-0.0921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>-0.4047</td>\n",
       "      <td>0.8507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>0.6280</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>1.5540</td>\n",
       "      <td>-0.0764</td>\n",
       "      <td>-0.0323</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>0.1715</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>1.2300</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>-0.5138</td>\n",
       "      <td>-0.2491</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>-0.8095</td>\n",
       "      <td>-1.9590</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>-0.1321</td>\n",
       "      <td>-1.0600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>-0.3254</td>\n",
       "      <td>-0.4009</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>1.4180</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>-0.2800</td>\n",
       "      <td>-0.1498</td>\n",
       "      <td>-0.8789</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 876 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 g-0     g-1     g-2     g-3     g-4     g-5     g-6     g-7  \\\n",
       "sig_id                                                                         \n",
       "id_000644bb2  1.0620  0.5577 -0.2479 -0.6208 -0.1944 -1.0120 -1.0220 -0.0326   \n",
       "id_000779bfc  0.0743  0.4087  0.2991  0.0604  1.0190  0.5207  0.2341  0.3372   \n",
       "id_000a6266a  0.6280  0.5817  1.5540 -0.0764 -0.0323  1.2390  0.1715  0.2155   \n",
       "id_0015fd391 -0.5138 -0.2491 -0.2656  0.5288  4.0620 -0.8095 -1.9590  0.1792   \n",
       "id_001626bd3 -0.3254 -0.4009  0.9700  0.6919  1.4180 -0.8244 -0.2800 -0.1498   \n",
       "\n",
       "                 g-8     g-9  ...    c-94    c-95    c-96    c-97    c-98  \\\n",
       "sig_id                        ...                                           \n",
       "id_000644bb2  0.5548 -0.0921  ... -0.1912  0.6584 -0.3981  0.2139  0.3801   \n",
       "id_000779bfc -0.4047  0.8507  ...  0.2957  0.4899  0.1522  0.1241  0.6077   \n",
       "id_000a6266a  0.0065  1.2300  ... -1.3240 -0.3174 -0.6417 -0.2187 -1.4080   \n",
       "id_0015fd391 -0.1321 -1.0600  ... -0.8632 -1.2880 -1.6210 -0.8784 -0.3876   \n",
       "id_001626bd3 -0.8789  0.8630  ...  0.5523 -0.3031  0.1094  0.2885 -0.3786   \n",
       "\n",
       "                c-99  cp_type_trt_cp  cp_dose_D2  cp_time_48  cp_time_72  \n",
       "sig_id                                                                    \n",
       "id_000644bb2  0.4176               1           0           0           0  \n",
       "id_000779bfc  0.7371               1           0           0           1  \n",
       "id_000a6266a  0.6931               1           0           1           0  \n",
       "id_0015fd391 -0.8154               1           0           1           0  \n",
       "id_001626bd3  0.7125               1           1           0           1  \n",
       "\n",
       "[5 rows x 876 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_b_dummies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23814, 876)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_b_dummies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below initializes a grid search with stratified kfold split for a custom model. Returns the best estimated model based on the chosen scoring strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cross_validation_multiple_targets(model, params, scoring, n_splits,x_train,y_train):\n",
    "    \"\"\"A function that takes as params initialized model object, parameters for the grid search, scoring strategy of the grid search,\n",
    "    number of splits for the cross validation, train features and train target. Returns the best estimated model.\"\"\"\n",
    "    k_fold = StratifiedKFold(n_splits = n_splits)\n",
    "    grid_search = GridSearchCV(model, params, scoring = scoring, cv = k_fold.split(x_train, y_train))\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cross_validation_multiple_targets_returngrid(model, params, scoring, n_splits,x_train,y_train):\n",
    "    \"\"\"A function that takes as params initialized model object, parameters for the grid search, scoring strategy of the grid search,\n",
    "    number of splits for the cross validation, train features and train target. Returns the grid.\"\"\"\n",
    "    k_fold = StratifiedKFold(n_splits = n_splits)\n",
    "    grid_search = GridSearchCV(model, params, scoring = scoring, cv = k_fold.split(x_train, y_train))\n",
    "    grid_search.fit(x_train, y_train)\n",
    "#     best_model = grid_search.best_estimator_\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_reduced=pd.read_csv(\"train_targets_reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_LogReg = {\n",
    "    \"C\": [0.001,0.01,0.1,1,10,100], \n",
    "    \"solver\": ['saga',  'lbfgs'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 19:19:13.627605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 20:10:08.120440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "model_list_LogReg_reduced={}\n",
    "for key, value in train_targets_reduced.iteritems():\n",
    "    try:\n",
    "        model_list_LogReg_reduced[key]=grid_search_cross_validation_multiple_targets(LogisticRegression(multi_class='auto'), params_LogReg, 'f1', 3,train_features_b_dummies,value)\n",
    "    except Exception as e:\n",
    "        print(e)    \n",
    "with open('model_list_logreg_reduced_auto.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_list_LogReg_reduced, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(datetime.datetime.now())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_logreg_reduced = pd.read_pickle(r'model_list_logreg_reduced_auto.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11-beta-hsd1_inhibitor': LogisticRegression(C=0.001, solver='saga'),\n",
       " 'antiarrhythmic': LogisticRegression(C=0.001, solver='saga'),\n",
       " 'bcr-abl_inhibitor': LogisticRegression(C=10),\n",
       " 'glutamate_receptor_agonist': LogisticRegression(C=0.001, solver='saga'),\n",
       " 'membrane_integrity_inhibitor': LogisticRegression(C=100),\n",
       " 'vitamin_d_receptor_agonist': LogisticRegression(C=100)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list_logreg_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Linear SVM with Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_LSVM={\n",
    "    \"C\":[0.1, 0.5, 1, 10, 50],     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>antiarrhythmic</th>\n",
       "      <th>bcr-abl_inhibitor</th>\n",
       "      <th>glutamate_receptor_agonist</th>\n",
       "      <th>membrane_integrity_inhibitor</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              11-beta-hsd1_inhibitor  antiarrhythmic  bcr-abl_inhibitor  \\\n",
       "sig_id                                                                    \n",
       "id_000644bb2                       0               0                  0   \n",
       "id_000779bfc                       0               0                  0   \n",
       "id_000a6266a                       0               0                  1   \n",
       "id_0015fd391                       0               0                  0   \n",
       "id_001626bd3                       0               0                  0   \n",
       "\n",
       "              glutamate_receptor_agonist  membrane_integrity_inhibitor  \\\n",
       "sig_id                                                                   \n",
       "id_000644bb2                           0                             0   \n",
       "id_000779bfc                           0                             0   \n",
       "id_000a6266a                           0                             0   \n",
       "id_0015fd391                           0                             0   \n",
       "id_001626bd3                           0                             0   \n",
       "\n",
       "              vitamin_d_receptor_agonist  \n",
       "sig_id                                    \n",
       "id_000644bb2                           0  \n",
       "id_000779bfc                           0  \n",
       "id_000a6266a                           0  \n",
       "id_0015fd391                           0  \n",
       "id_001626bd3                           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_reduced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SelectPercentile computes the ANOVA F-value. The independent variables in ANOVA must be categorical variables Preserves the specified precentile of features with highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 09:50:52.530607\n",
      "1  vitamin_d_receptor_agonist\n",
      "2  SVC(C=0.1, kernel='linear')\n",
      "2020-11-11 09:55:57.722400\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "\n",
    "model_list_LSVM_reduced={}\n",
    "for key, value in train_targets_reduced.iteritems():    \n",
    "        try:\n",
    "            print(\"1 \",key)\n",
    "            x1 = SelectPercentile(mutual_info_classif, percentile=10).fit_transform(train_features_b_dummies.iloc[:,0:438], value)\n",
    "            x2 = SelectPercentile(mutual_info_classif, percentile=10).fit_transform(train_features_b_dummies.iloc[:,438:876], value)\n",
    "            x = np.concatenate((x1, x2),axis=1)\n",
    "\n",
    "            model_list_LSVM_reduced[key]=grid_search_cross_validation_multiple_targets(SVC(kernel='linear'), params_LSVM, 'f1', 3,x,value)\n",
    "\n",
    "            print(\"2 \",model_list_LSVM_reduced[key])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            continue    \n",
    "with open('model_list_LSVM_reduced0.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_list_LSVM_reduced, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(datetime.datetime.now())     \n",
    "#     print(type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth - the longest path between the root node and the leaf node\n",
    "# n_estimators - the number of trees\n",
    "\n",
    "params_RF={\n",
    "    \"n_estimators\":[50, 100, 200],\n",
    "    \"max_depth\":[20, 50, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 10:38:19.006940\n",
      "antiarrhythmic\n",
      "bcr-abl_inhibitor\n",
      "glutamate_receptor_agonist\n",
      "membrane_integrity_inhibitor\n",
      "vitamin_d_receptor_agonist\n",
      "2020-11-11 12:10:38.413646\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "model_list_RF={}\n",
    "for key, value in train_targets_reduced.iteritems(): \n",
    "        print(key)\n",
    "        try:\n",
    "            model_list_RF[key]=grid_search_cross_validation_multiple_targets(RandomForestClassifier(), params_RF, 'f1', 3,train_features_b_dummies,value)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "with open('model_list_RF_reduced.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_list_RF, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(datetime.datetime.now())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Logistic Regression with Under and Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones= np.count_nonzero(train_targets_reduced==1, axis=0)\n",
    "np.unique(ones,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())\n",
    "ratios = [0.003,0.006,0.02,0.02,0.04,0.04]\n",
    "model_list_LogReg_reduced_over_under={}\n",
    "model_estimates_train = defaultdict(list)\n",
    "\n",
    "for key, value in train_targets_reduced.iteritems():\n",
    "    \n",
    "    undersample = RandomUnderSampler(sampling_strategy=ratios[i])\n",
    "    oversample = SMOTE(sampling_strategy=0.5)\n",
    "    \n",
    "        steps = [('u', undersample),('o', oversample)]\n",
    "        pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "        try:\n",
    "            x, y = pipeline.fit_resample(train_features_b_dummies, value)\n",
    "     \n",
    "            model=grid_search_cross_validation_multiple_targets_returngrid(LogisticRegression(multi_class='auto'), params_LogReg, 'f1', 3,x,y)\n",
    "            model_list_LogReg_reduced_over_under[key] = model.best_estimator_\n",
    "            model_estimates_train['model_logreg_over_under'].append(model.best_score_)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)    \n",
    "with open('model_list_logreg_reduced_auto_over_under2.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_list_LogReg_reduced_over_under, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "model_estimates_train=pd.DataFrame(model_estimates_train)\n",
    "model_estimates_train.to_csv(\"model_estimates_train_logreg_over_under2.csv\")\n",
    "print(datetime.datetime.now()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Check for Under/Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_logreg_reduced = pd.read_pickle(r'model_list_logreg_reduced_auto.pickle')\n",
    "model_list_logreg_reduced_under_over = pd.read_pickle(r'model_list_logreg_reduced_auto_over_under2.pickle')\n",
    "model_list_LSVM_reduced = pd.read_pickle(r'model_list_LSVM_reduced0.pickle')\n",
    "model_list_RF_reduced = pd.read_pickle(r'model_list_RF_reduced.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model_estimates_train = defaultdict(list)\n",
    "model_estimates_validate = defaultdict(list)\n",
    "\n",
    "for key,value in train_targets_reduced.iteritems():\n",
    "    \n",
    "    model_logreg = model_list_logreg_reduced[key]\n",
    "    model_logreg_under_over = model_list_logreg_reduced_under_over[key]\n",
    "    model_RF = model_list_RF_reduced[key]\n",
    "    \n",
    "    train_features_train, train_features_validate, train_targets_train, train_targets_validate = train_test_split(\n",
    "    train_features_b_dummies, value, train_size = 0.7, stratify = value)\n",
    "    \n",
    "    model_logreg.fit(train_features_train, train_targets_train)\n",
    "    model_logreg_under_over.fit(train_features_train, train_targets_train)\n",
    "    model_RF.fit(train_features_train, train_targets_train)\n",
    "\n",
    "\n",
    "    model_estimates_train['model_logreg'].append(model_logreg.score(train_features_train, train_targets_train))\n",
    "    model_estimates_validate['model_logreg'].append(f1_score(train_targets_validate, model_logreg.predict(train_features_validate)))\n",
    "    \n",
    "    model_estimates_train['model_logreg_under_over'].append(model_logreg_under_over.score(train_features_train, train_targets_train))\n",
    "    model_estimates_validate['model_logreg_under_over'].append(f1_score(train_targets_validate, model_logreg_under_over.predict(train_features_validate)))\n",
    "    \n",
    "    model_estimates_train['model_RF'].append(model_RF.score(train_features_train, train_targets_train))\n",
    "    model_estimates_validate['model_RF'].append(f1_score(train_targets_validate, model_RF.predict(train_features_validate)))\n",
    "\n",
    "model_estimates_train=pd.DataFrame(model_estimates_train)\n",
    "model_estimates_validate=pd.DataFrame(model_estimates_validate)\n",
    "\n",
    "model_estimates_train.to_csv(\"model_estimates_train2.csv\")\n",
    "model_estimates_validate.to_csv(\"model_estimates_validate2.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_estimates_train = pd.read_csv('model_estimates_train2.csv')\n",
    "model_estimates_validate=pd.read_csv('model_estimates_validate2.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_logreg</th>\n",
       "      <th>model_logreg_under_over</th>\n",
       "      <th>model_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  model_logreg  model_logreg_under_over  model_RF\n",
       "0           0      0.000000                 0.000000       0.0\n",
       "1           1      0.000000                 0.000000       0.0\n",
       "2           2      0.428571                 0.428571       0.0\n",
       "3           3      0.000000                 0.000000       0.0\n",
       "4           4      0.000000                 0.000000       0.0\n",
       "5           5      0.470588                 0.153846       0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimates_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model_logreg</th>\n",
       "      <th>model_logreg_under_over</th>\n",
       "      <th>model_RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.99922</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99976</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.99688</td>\n",
       "      <td>0.99892</td>\n",
       "      <td>0.99982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99844</td>\n",
       "      <td>0.99994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.99898</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  model_logreg  model_logreg_under_over  model_RF\n",
       "0           0       0.99922                  1.00000   1.00000\n",
       "1           1       0.99976                  1.00000   1.00000\n",
       "2           2       1.00000                  1.00000   1.00000\n",
       "3           3       0.99688                  0.99892   0.99982\n",
       "4           4       1.00000                  0.99844   0.99994\n",
       "5           5       1.00000                  0.99898   1.00000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimates_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "Drafts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_batches(df,percent_threshold,n_components,*args):\n",
    "    \"\"\"args is a list with the boundaires of the df for which PCA will be applied\"\"\"\n",
    "    batch_list = []\n",
    "    pca_list  =[]\n",
    "    for index in range(len(args)-1):\n",
    "        df_PCA = df.iloc[:,args[index]:args[index+1]]\n",
    "        batch_list.append(df_PCA)\n",
    "    for batch in batch_list:\n",
    "        pca = PCA(n_components=n_components).fit_transform(batch)\n",
    "        pca_df = pd.DataFrame(pca)\n",
    "        pca_list.append(pca_df)\n",
    "    df_final = reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True,how='outer'), pca_list) \n",
    "    return df_final\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_df = PCA_batches(train_features_b_dummies,'percent_threshold',3,0,300,600,800,872)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.723137</td>\n",
       "      <td>0.533568</td>\n",
       "      <td>-0.653711</td>\n",
       "      <td>-4.935411</td>\n",
       "      <td>-1.298509</td>\n",
       "      <td>-1.328726</td>\n",
       "      <td>-5.130583</td>\n",
       "      <td>0.282565</td>\n",
       "      <td>-3.944394</td>\n",
       "      <td>-6.190893</td>\n",
       "      <td>-0.074689</td>\n",
       "      <td>0.347022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.067255</td>\n",
       "      <td>1.361307</td>\n",
       "      <td>5.590406</td>\n",
       "      <td>-4.309550</td>\n",
       "      <td>3.364243</td>\n",
       "      <td>6.069413</td>\n",
       "      <td>-5.346431</td>\n",
       "      <td>0.760029</td>\n",
       "      <td>1.804479</td>\n",
       "      <td>-6.050393</td>\n",
       "      <td>-0.671079</td>\n",
       "      <td>0.106307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.773748</td>\n",
       "      <td>2.521646</td>\n",
       "      <td>-1.452083</td>\n",
       "      <td>-0.119953</td>\n",
       "      <td>0.898035</td>\n",
       "      <td>0.732229</td>\n",
       "      <td>-2.549519</td>\n",
       "      <td>0.891472</td>\n",
       "      <td>2.155023</td>\n",
       "      <td>-1.972984</td>\n",
       "      <td>0.310375</td>\n",
       "      <td>0.576631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.968533</td>\n",
       "      <td>-2.167132</td>\n",
       "      <td>-3.226692</td>\n",
       "      <td>5.375589</td>\n",
       "      <td>-3.518999</td>\n",
       "      <td>-0.393909</td>\n",
       "      <td>9.176148</td>\n",
       "      <td>-3.364282</td>\n",
       "      <td>3.820734</td>\n",
       "      <td>11.238751</td>\n",
       "      <td>6.424056</td>\n",
       "      <td>-0.123428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.165412</td>\n",
       "      <td>1.268963</td>\n",
       "      <td>5.181918</td>\n",
       "      <td>-4.853418</td>\n",
       "      <td>-0.427602</td>\n",
       "      <td>4.733241</td>\n",
       "      <td>-3.979105</td>\n",
       "      <td>-1.179680</td>\n",
       "      <td>2.714048</td>\n",
       "      <td>-5.293675</td>\n",
       "      <td>0.898601</td>\n",
       "      <td>0.054930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_x       1_x       2_x       0_y       1_y       2_y       0_x  \\\n",
       "0 -5.723137  0.533568 -0.653711 -4.935411 -1.298509 -1.328726 -5.130583   \n",
       "1 -4.067255  1.361307  5.590406 -4.309550  3.364243  6.069413 -5.346431   \n",
       "2 -0.773748  2.521646 -1.452083 -0.119953  0.898035  0.732229 -2.549519   \n",
       "3  5.968533 -2.167132 -3.226692  5.375589 -3.518999 -0.393909  9.176148   \n",
       "4 -5.165412  1.268963  5.181918 -4.853418 -0.427602  4.733241 -3.979105   \n",
       "\n",
       "        1_x       2_x        0_y       1_y       2_y  \n",
       "0  0.282565 -3.944394  -6.190893 -0.074689  0.347022  \n",
       "1  0.760029  1.804479  -6.050393 -0.671079  0.106307  \n",
       "2  0.891472  2.155023  -1.972984  0.310375  0.576631  \n",
       "3 -3.364282  3.820734  11.238751  6.424056 -0.123428  \n",
       "4 -1.179680  2.714048  -5.293675  0.898601  0.054930  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_miss_features=PCA_df_final.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_miss_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = train_features_b_dummies.iloc[:,-4::]\n",
    "train_dummies=train_dummies.reset_index(drop=True)\n",
    "PCA_df_final = pd.merge(PCA_df, train_dummies, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>cp_type_trt_cp</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.723137</td>\n",
       "      <td>0.533568</td>\n",
       "      <td>-0.653711</td>\n",
       "      <td>-4.935411</td>\n",
       "      <td>-1.298509</td>\n",
       "      <td>-1.328726</td>\n",
       "      <td>-5.130583</td>\n",
       "      <td>0.282565</td>\n",
       "      <td>-3.944394</td>\n",
       "      <td>-6.190893</td>\n",
       "      <td>-0.074689</td>\n",
       "      <td>0.347022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.067255</td>\n",
       "      <td>1.361307</td>\n",
       "      <td>5.590406</td>\n",
       "      <td>-4.309550</td>\n",
       "      <td>3.364243</td>\n",
       "      <td>6.069413</td>\n",
       "      <td>-5.346431</td>\n",
       "      <td>0.760029</td>\n",
       "      <td>1.804479</td>\n",
       "      <td>-6.050393</td>\n",
       "      <td>-0.671079</td>\n",
       "      <td>0.106307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.773748</td>\n",
       "      <td>2.521646</td>\n",
       "      <td>-1.452083</td>\n",
       "      <td>-0.119953</td>\n",
       "      <td>0.898035</td>\n",
       "      <td>0.732229</td>\n",
       "      <td>-2.549519</td>\n",
       "      <td>0.891472</td>\n",
       "      <td>2.155023</td>\n",
       "      <td>-1.972984</td>\n",
       "      <td>0.310375</td>\n",
       "      <td>0.576631</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.968533</td>\n",
       "      <td>-2.167132</td>\n",
       "      <td>-3.226692</td>\n",
       "      <td>5.375589</td>\n",
       "      <td>-3.518999</td>\n",
       "      <td>-0.393909</td>\n",
       "      <td>9.176148</td>\n",
       "      <td>-3.364282</td>\n",
       "      <td>3.820734</td>\n",
       "      <td>11.238751</td>\n",
       "      <td>6.424056</td>\n",
       "      <td>-0.123428</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.165412</td>\n",
       "      <td>1.268963</td>\n",
       "      <td>5.181918</td>\n",
       "      <td>-4.853418</td>\n",
       "      <td>-0.427602</td>\n",
       "      <td>4.733241</td>\n",
       "      <td>-3.979105</td>\n",
       "      <td>-1.179680</td>\n",
       "      <td>2.714048</td>\n",
       "      <td>-5.293675</td>\n",
       "      <td>0.898601</td>\n",
       "      <td>0.054930</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_x       1_x       2_x       0_y       1_y       2_y       0_x  \\\n",
       "0 -5.723137  0.533568 -0.653711 -4.935411 -1.298509 -1.328726 -5.130583   \n",
       "1 -4.067255  1.361307  5.590406 -4.309550  3.364243  6.069413 -5.346431   \n",
       "2 -0.773748  2.521646 -1.452083 -0.119953  0.898035  0.732229 -2.549519   \n",
       "3  5.968533 -2.167132 -3.226692  5.375589 -3.518999 -0.393909  9.176148   \n",
       "4 -5.165412  1.268963  5.181918 -4.853418 -0.427602  4.733241 -3.979105   \n",
       "\n",
       "        1_x       2_x        0_y       1_y       2_y  cp_type_trt_cp  \\\n",
       "0  0.282565 -3.944394  -6.190893 -0.074689  0.347022               1   \n",
       "1  0.760029  1.804479  -6.050393 -0.671079  0.106307               1   \n",
       "2  0.891472  2.155023  -1.972984  0.310375  0.576631               1   \n",
       "3 -3.364282  3.820734  11.238751  6.424056 -0.123428               1   \n",
       "4 -1.179680  2.714048  -5.293675  0.898601  0.054930               1   \n",
       "\n",
       "   cp_dose_D2  cp_time_48  cp_time_72  \n",
       "0           0           0           0  \n",
       "1           0           0           1  \n",
       "2           0           1           0  \n",
       "3           0           1           0  \n",
       "4           1           0           1  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA_df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "moa_features_train, moa_features_validate,moa_targets_train_2,moa_targets_validate_2 = train_test_split(PCA_df_final,train_targets_0,train_size = 0.7,stratify=train_targets_0)\n",
    "log_reg_2 = LogisticRegression(C=10)\n",
    "log_reg_2 = log_reg_2.fit(moa_features_train,moa_targets_train_2)\n",
    "accuracy_score = log_reg_2.score(moa_features_validate,moa_targets_validate_2)\n",
    "ascore=metrics.accuracy_score(moa_targets_validate_2,log_reg_2.predict(moa_features_validate))\n",
    "fscore=metrics.f1_score(moa_targets_validate_2,log_reg_2.predict(moa_features_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874037788663401"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n",
      "(1, 3, 4, 5)\n",
      "range(0, 4)\n"
     ]
    }
   ],
   "source": [
    "tt('df',1,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_one = train_features_b_dummies.iloc[:,0:300]\n",
    "batch_two = train_features_b_dummies.iloc[:,301:600]\n",
    "batch_three = train_features_b_dummies.iloc[:,601:800]\n",
    "batch_four = train_features_b_dummies.iloc[:,801:872]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "      <th>cp_type_trt_cp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                c-98    c-99  cp_type_trt_cp\n",
       "sig_id                                      \n",
       "id_000644bb2  0.3801  0.4176               1\n",
       "id_000779bfc  0.6077  0.7371               1\n",
       "id_000a6266a -1.4080  0.6931               1\n",
       "id_0015fd391 -0.3876 -0.8154               1\n",
       "id_001626bd3 -0.3786  0.7125               1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_b_dummies.iloc[0:5,870:873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g-601</th>\n",
       "      <th>g-602</th>\n",
       "      <th>g-603</th>\n",
       "      <th>g-604</th>\n",
       "      <th>g-605</th>\n",
       "      <th>g-606</th>\n",
       "      <th>g-607</th>\n",
       "      <th>g-608</th>\n",
       "      <th>g-609</th>\n",
       "      <th>g-610</th>\n",
       "      <th>...</th>\n",
       "      <th>c-90</th>\n",
       "      <th>c-91</th>\n",
       "      <th>c-92</th>\n",
       "      <th>c-93</th>\n",
       "      <th>c-94</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id_000644bb2</th>\n",
       "      <td>-0.2136</td>\n",
       "      <td>-0.6129</td>\n",
       "      <td>0.4357</td>\n",
       "      <td>1.2690</td>\n",
       "      <td>-0.3858</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>3.3940</td>\n",
       "      <td>-0.0452</td>\n",
       "      <td>0.6513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.1912</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>-0.3981</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.3801</td>\n",
       "      <td>0.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000779bfc</th>\n",
       "      <td>0.8543</td>\n",
       "      <td>1.2990</td>\n",
       "      <td>-1.1020</td>\n",
       "      <td>-0.6565</td>\n",
       "      <td>-1.0050</td>\n",
       "      <td>-0.8245</td>\n",
       "      <td>-0.9344</td>\n",
       "      <td>1.1400</td>\n",
       "      <td>0.8501</td>\n",
       "      <td>-0.7063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4265</td>\n",
       "      <td>0.7543</td>\n",
       "      <td>0.4708</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2957</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_000a6266a</th>\n",
       "      <td>-0.3010</td>\n",
       "      <td>2.8890</td>\n",
       "      <td>1.3400</td>\n",
       "      <td>1.4570</td>\n",
       "      <td>4.4760</td>\n",
       "      <td>-1.5700</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>2.2500</td>\n",
       "      <td>0.2751</td>\n",
       "      <td>-0.2307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7250</td>\n",
       "      <td>-0.6297</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>-1.3240</td>\n",
       "      <td>-0.3174</td>\n",
       "      <td>-0.6417</td>\n",
       "      <td>-0.2187</td>\n",
       "      <td>-1.4080</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_0015fd391</th>\n",
       "      <td>-1.8150</td>\n",
       "      <td>-0.8354</td>\n",
       "      <td>1.7400</td>\n",
       "      <td>-0.4051</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>1.8750</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>-1.5450</td>\n",
       "      <td>-1.3680</td>\n",
       "      <td>0.3007</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0990</td>\n",
       "      <td>-0.6441</td>\n",
       "      <td>-5.6300</td>\n",
       "      <td>-1.3780</td>\n",
       "      <td>-0.8632</td>\n",
       "      <td>-1.2880</td>\n",
       "      <td>-1.6210</td>\n",
       "      <td>-0.8784</td>\n",
       "      <td>-0.3876</td>\n",
       "      <td>-0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_001626bd3</th>\n",
       "      <td>0.8249</td>\n",
       "      <td>-0.0131</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>0.1662</td>\n",
       "      <td>-0.3453</td>\n",
       "      <td>1.3360</td>\n",
       "      <td>-0.3655</td>\n",
       "      <td>-0.6961</td>\n",
       "      <td>-0.4308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>1.0690</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>-0.3031</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>-0.3786</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               g-601   g-602   g-603   g-604   g-605   g-606   g-607   g-608  \\\n",
       "sig_id                                                                         \n",
       "id_000644bb2 -0.2136 -0.6129  0.4357  1.2690 -0.3858  0.8604  0.0958  3.3940   \n",
       "id_000779bfc  0.8543  1.2990 -1.1020 -0.6565 -1.0050 -0.8245 -0.9344  1.1400   \n",
       "id_000a6266a -0.3010  2.8890  1.3400  1.4570  4.4760 -1.5700  0.6040  2.2500   \n",
       "id_0015fd391 -1.8150 -0.8354  1.7400 -0.4051  0.4205  1.8750  0.8082 -1.5450   \n",
       "id_001626bd3  0.8249 -0.0131  0.0000  0.9043  0.1662 -0.3453  1.3360 -0.3655   \n",
       "\n",
       "               g-609   g-610  ...    c-90    c-91    c-92    c-93    c-94  \\\n",
       "sig_id                        ...                                           \n",
       "id_000644bb2 -0.0452  0.6513  ...  0.2862  0.2584  0.8076  0.5523 -0.1912   \n",
       "id_000779bfc  0.8501 -0.7063  ... -0.4265  0.7543  0.4708  0.0230  0.2957   \n",
       "id_000a6266a  0.2751 -0.2307  ... -0.7250 -0.6297  0.6103  0.0223 -1.3240   \n",
       "id_0015fd391 -1.3680  0.3007  ... -2.0990 -0.6441 -5.6300 -1.3780 -0.8632   \n",
       "id_001626bd3 -0.6961 -0.4308  ...  0.0042  0.0048  0.6670  1.0690  0.5523   \n",
       "\n",
       "                c-95    c-96    c-97    c-98    c-99  \n",
       "sig_id                                                \n",
       "id_000644bb2  0.6584 -0.3981  0.2139  0.3801  0.4176  \n",
       "id_000779bfc  0.4899  0.1522  0.1241  0.6077  0.7371  \n",
       "id_000a6266a -0.3174 -0.6417 -0.2187 -1.4080  0.6931  \n",
       "id_0015fd391 -1.2880 -1.6210 -0.8784 -0.3876 -0.8154  \n",
       "id_001626bd3 -0.3031  0.1094  0.2885 -0.3786  0.7125  \n",
       "\n",
       "[5 rows x 271 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_three.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_one = PCA(n_components=5).fit(batch_one)\n",
    "pca_two = PCA(n_components=5).fit(batch_two)\n",
    "pca_three = PCA(n_components=5).fit(batch_three)\n",
    "pca_four_1 = PCA(n_components=5).fit(batch_four_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32770748 0.05083023 0.03325614 0.02710047 0.02460508]\n",
      "[0.28062958 0.04749156 0.03269229 0.02955473 0.02317879]\n",
      "[0.43511607 0.03444596 0.02538106 0.02125228 0.02102561]\n",
      "[0.84822599 0.01118344 0.00856168 0.00662918 0.00509189]\n"
     ]
    }
   ],
   "source": [
    "print(pca_one.explained_variance_ratio_)\n",
    "print(pca_two.explained_variance_ratio_)\n",
    "print(pca_three.explained_variance_ratio_)\n",
    "print(pca_four_1.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one = pca_one.transform(batch_one)\n",
    "train_one_df = pd.DataFrame(train_one)\n",
    "train_two = pca_two.transform(batch_two)\n",
    "train_two_df = pd.DataFrame(train_two)\n",
    "train_three = pca_three.transform(batch_three)\n",
    "train_three_df = pd.DataFrame(train_three)\n",
    "train_four = pca_four_1.transform(batch_four_1)\n",
    "train_four_df = pd.DataFrame(train_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_five_df = train_features_b_dummies.iloc[:,-4::]\n",
    "train_five_df=train_five_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cp_type_trt_cp</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cp_type_trt_cp  cp_dose_D2  cp_time_48  cp_time_72\n",
       "0               1           0           0           0\n",
       "1               1           0           0           1\n",
       "2               1           0           1           0\n",
       "3               1           0           1           0\n",
       "4               1           1           0           1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_five_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_one_df, train_two_df, train_three_df, train_four_df,train_five_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = reduce(lambda left,right: pd.merge(left,right,left_index=True, right_index=True,how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>3_y</th>\n",
       "      <th>4_y</th>\n",
       "      <th>...</th>\n",
       "      <th>4_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>3_y</th>\n",
       "      <th>4_y</th>\n",
       "      <th>cp_type_trt_cp</th>\n",
       "      <th>cp_dose_D2</th>\n",
       "      <th>cp_time_48</th>\n",
       "      <th>cp_time_72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>23814.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>2.381400e+04</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.864370e-17</td>\n",
       "      <td>4.057857e-17</td>\n",
       "      <td>4.773950e-18</td>\n",
       "      <td>-3.222416e-17</td>\n",
       "      <td>-1.790231e-18</td>\n",
       "      <td>1.909580e-17</td>\n",
       "      <td>-1.909580e-17</td>\n",
       "      <td>1.193487e-18</td>\n",
       "      <td>2.088603e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.193487e-18</td>\n",
       "      <td>-3.437244e-16</td>\n",
       "      <td>1.909580e-17</td>\n",
       "      <td>1.253162e-17</td>\n",
       "      <td>-1.790231e-18</td>\n",
       "      <td>1.163650e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.244796e+01</td>\n",
       "      <td>4.902482e+00</td>\n",
       "      <td>3.965435e+00</td>\n",
       "      <td>3.579673e+00</td>\n",
       "      <td>3.410887e+00</td>\n",
       "      <td>1.090857e+01</td>\n",
       "      <td>4.487550e+00</td>\n",
       "      <td>3.723264e+00</td>\n",
       "      <td>3.540092e+00</td>\n",
       "      <td>3.135064</td>\n",
       "      <td>...</td>\n",
       "      <td>2.719167e+00</td>\n",
       "      <td>1.468869e+01</td>\n",
       "      <td>1.686612e+00</td>\n",
       "      <td>1.475730e+00</td>\n",
       "      <td>1.298546e+00</td>\n",
       "      <td>1.138070e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>0.547723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.058428e+01</td>\n",
       "      <td>-3.303776e+01</td>\n",
       "      <td>-2.761524e+01</td>\n",
       "      <td>-1.946286e+01</td>\n",
       "      <td>-2.429581e+01</td>\n",
       "      <td>-9.643162e+00</td>\n",
       "      <td>-2.810857e+01</td>\n",
       "      <td>-2.030038e+01</td>\n",
       "      <td>-2.965857e+01</td>\n",
       "      <td>-20.420271</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430184e+01</td>\n",
       "      <td>-2.812005e+01</td>\n",
       "      <td>-6.167411e+00</td>\n",
       "      <td>-7.691083e+00</td>\n",
       "      <td>-7.585031e+00</td>\n",
       "      <td>-7.741625e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.658164e+00</td>\n",
       "      <td>-5.962459e-01</td>\n",
       "      <td>-1.795878e+00</td>\n",
       "      <td>-1.572020e+00</td>\n",
       "      <td>-1.721755e+00</td>\n",
       "      <td>-4.296404e+00</td>\n",
       "      <td>-6.526442e-01</td>\n",
       "      <td>-1.893137e+00</td>\n",
       "      <td>-1.965562e+00</td>\n",
       "      <td>-1.328586</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.533016e+00</td>\n",
       "      <td>-5.757927e+00</td>\n",
       "      <td>-6.360690e-01</td>\n",
       "      <td>-5.870047e-01</td>\n",
       "      <td>-5.677250e-01</td>\n",
       "      <td>-4.992804e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.551164e+00</td>\n",
       "      <td>5.701192e-01</td>\n",
       "      <td>1.411947e-01</td>\n",
       "      <td>-4.860308e-02</td>\n",
       "      <td>-7.886032e-02</td>\n",
       "      <td>-3.279072e+00</td>\n",
       "      <td>4.003440e-01</td>\n",
       "      <td>7.819578e-02</td>\n",
       "      <td>6.672985e-02</td>\n",
       "      <td>-0.188821</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.136600e-02</td>\n",
       "      <td>-3.789666e+00</td>\n",
       "      <td>-1.860991e-01</td>\n",
       "      <td>-1.036299e-01</td>\n",
       "      <td>-1.088893e-01</td>\n",
       "      <td>-4.510919e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-2.033061e+00</td>\n",
       "      <td>1.576018e+00</td>\n",
       "      <td>2.014944e+00</td>\n",
       "      <td>1.419960e+00</td>\n",
       "      <td>1.652765e+00</td>\n",
       "      <td>-1.778540e+00</td>\n",
       "      <td>1.305364e+00</td>\n",
       "      <td>2.001572e+00</td>\n",
       "      <td>2.029174e+00</td>\n",
       "      <td>1.007580</td>\n",
       "      <td>...</td>\n",
       "      <td>1.497076e+00</td>\n",
       "      <td>-1.268764e+00</td>\n",
       "      <td>2.974075e-01</td>\n",
       "      <td>3.974713e-01</td>\n",
       "      <td>4.067373e-01</td>\n",
       "      <td>4.103897e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.515219e+01</td>\n",
       "      <td>3.388349e+01</td>\n",
       "      <td>2.880539e+01</td>\n",
       "      <td>2.995750e+01</td>\n",
       "      <td>3.575685e+01</td>\n",
       "      <td>6.832289e+01</td>\n",
       "      <td>3.606325e+01</td>\n",
       "      <td>2.521791e+01</td>\n",
       "      <td>3.111762e+01</td>\n",
       "      <td>23.530678</td>\n",
       "      <td>...</td>\n",
       "      <td>2.253682e+01</td>\n",
       "      <td>7.850483e+01</td>\n",
       "      <td>1.641736e+01</td>\n",
       "      <td>1.291604e+01</td>\n",
       "      <td>1.008105e+01</td>\n",
       "      <td>1.455192e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0_x           1_x           2_x           3_x           4_x  \\\n",
       "count  2.381400e+04  2.381400e+04  2.381400e+04  2.381400e+04  2.381400e+04   \n",
       "mean  -2.864370e-17  4.057857e-17  4.773950e-18 -3.222416e-17 -1.790231e-18   \n",
       "std    1.244796e+01  4.902482e+00  3.965435e+00  3.579673e+00  3.410887e+00   \n",
       "min   -1.058428e+01 -3.303776e+01 -2.761524e+01 -1.946286e+01 -2.429581e+01   \n",
       "25%   -4.658164e+00 -5.962459e-01 -1.795878e+00 -1.572020e+00 -1.721755e+00   \n",
       "50%   -3.551164e+00  5.701192e-01  1.411947e-01 -4.860308e-02 -7.886032e-02   \n",
       "75%   -2.033061e+00  1.576018e+00  2.014944e+00  1.419960e+00  1.652765e+00   \n",
       "max    7.515219e+01  3.388349e+01  2.880539e+01  2.995750e+01  3.575685e+01   \n",
       "\n",
       "                0_y           1_y           2_y           3_y           4_y  \\\n",
       "count  2.381400e+04  2.381400e+04  2.381400e+04  2.381400e+04  23814.000000   \n",
       "mean   1.909580e-17 -1.909580e-17  1.193487e-18  2.088603e-17      0.000000   \n",
       "std    1.090857e+01  4.487550e+00  3.723264e+00  3.540092e+00      3.135064   \n",
       "min   -9.643162e+00 -2.810857e+01 -2.030038e+01 -2.965857e+01    -20.420271   \n",
       "25%   -4.296404e+00 -6.526442e-01 -1.893137e+00 -1.965562e+00     -1.328586   \n",
       "50%   -3.279072e+00  4.003440e-01  7.819578e-02  6.672985e-02     -0.188821   \n",
       "75%   -1.778540e+00  1.305364e+00  2.001572e+00  2.029174e+00      1.007580   \n",
       "max    6.832289e+01  3.606325e+01  2.521791e+01  3.111762e+01     23.530678   \n",
       "\n",
       "       ...           4_x           0_y           1_y           2_y  \\\n",
       "count  ...  2.381400e+04  2.381400e+04  2.381400e+04  2.381400e+04   \n",
       "mean   ... -1.193487e-18 -3.437244e-16  1.909580e-17  1.253162e-17   \n",
       "std    ...  2.719167e+00  1.468869e+01  1.686612e+00  1.475730e+00   \n",
       "min    ... -1.430184e+01 -2.812005e+01 -6.167411e+00 -7.691083e+00   \n",
       "25%    ... -1.533016e+00 -5.757927e+00 -6.360690e-01 -5.870047e-01   \n",
       "50%    ... -4.136600e-02 -3.789666e+00 -1.860991e-01 -1.036299e-01   \n",
       "75%    ...  1.497076e+00 -1.268764e+00  2.974075e-01  3.974713e-01   \n",
       "max    ...  2.253682e+01  7.850483e+01  1.641736e+01  1.291604e+01   \n",
       "\n",
       "                3_y           4_y  cp_type_trt_cp  cp_dose_D2  cp_time_48  \\\n",
       "count  2.381400e+04  2.381400e+04             5.0    5.000000    5.000000   \n",
       "mean  -1.790231e-18  1.163650e-17             1.0    0.200000    0.400000   \n",
       "std    1.298546e+00  1.138070e+00             0.0    0.447214    0.547723   \n",
       "min   -7.585031e+00 -7.741625e+00             1.0    0.000000    0.000000   \n",
       "25%   -5.677250e-01 -4.992804e-01             1.0    0.000000    0.000000   \n",
       "50%   -1.088893e-01 -4.510919e-02             1.0    0.000000    0.000000   \n",
       "75%    4.067373e-01  4.103897e-01             1.0    0.000000    1.000000   \n",
       "max    1.008105e+01  1.455192e+01             1.0    1.000000    1.000000   \n",
       "\n",
       "       cp_time_72  \n",
       "count    5.000000  \n",
       "mean     0.400000  \n",
       "std      0.547723  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95236"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_miss_features=df_final.isnull().sum().sum()\n",
    "df_final_miss_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_0=train_targets.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_features_train, moa_features_validate,moa_targets_train_0,moa_targets_validate_0 = train_test_split(train_features_b_dummies,train_targets_0,train_size = 0.7,stratify=train_targets_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9764870538838348"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_0 = LogisticRegression(C=1)\n",
    "log_reg_0 = log_reg_0.fit(moa_features_train,moa_targets_train_0)\n",
    "accuracy_score = log_reg_0.score(moa_features_validate,moa_targets_validate_0)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = log_reg_0.predict(moa_features_validate)\n",
    "np_ones_0= np.count_nonzero(prediction, axis=0)\n",
    "np_ones_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score=  metrics.f1_score(moa_targets_validate_0,log_reg_0.predict(moa_features_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011764705882352941"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascore=metrics.accuracy_score(moa_targets_validate_0,log_reg_0.predict(moa_features_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764870538838348"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_features_train_pca, moa_features_validate_pca,moa_targets_train_0,moa_targets_validate_0 = train_test_split(df_final,train_targets_0,train_size = 0.7,stratify=train_targets_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-38c927a00e1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlog_reg_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlog_reg_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoa_features_train_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmoa_targets_train_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maccuracy_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoa_features_validate_pca\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmoa_targets_validate_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1532\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "log_reg_0 = LogisticRegression(C=1e6)\n",
    "log_reg_0 = log_reg_0.fit(moa_features_train_pca,moa_targets_train_0)\n",
    "accuracy_score = log_reg_0.score(moa_features_validate_pca,moa_targets_validate_0)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = log_reg_0.predict(moa_features_validate)\n",
    "np_ones_0= np.count_nonzero(prediction, axis=0)\n",
    "np_ones_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-dbe5850057a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mipca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIncrementalPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features_b_dummies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# train_features_b_dummies_pca = pca.transform(train_features_b_dummies)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\decomposition\\incremental_pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoise_variance_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1904\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1905\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5378\u001b[0m                [nan,  3.]])\n\u001b[0;32m   5379\u001b[0m         \"\"\"\n\u001b[1;32m-> 5380\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5323\u001b[0m         \"\"\"\n\u001b[0;32m   5324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5325\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5327\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, items)\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtranspose\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ipca = IncrementalPCA(batch_size=10).fit(train_features_b_dummies)\n",
    "# train_features_b_dummies_pca = pca.transform(train_features_b_dummies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_0=train_targets.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sig_id\n",
       "id_000644bb2    0\n",
       "id_000779bfc    0\n",
       "id_000a6266a    0\n",
       "id_0015fd391    0\n",
       "id_001626bd3    0\n",
       "Name: 5-alpha_reductase_inhibitor, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets_0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "moa_features_train, moa_features_validate,moa_targets_train_0,moa_targets_validate_0 = train_test_split(train_features_b_dummies,train_targets_0,train_size = 0.7,stratify=train_targets_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sig_id\n",
       "id_8e129929f    0\n",
       "id_7b799c0a0    0\n",
       "id_b3cdf9013    0\n",
       "id_85f34ba96    0\n",
       "id_ddb909340    0\n",
       "Name: 5-alpha_reductase_inhibitor, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moa_targets_train_0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-3aaa65c3e916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlog_reg_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlog_reg_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoa_features_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmoa_targets_train_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1532\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_reg_0 = LogisticRegression(C=1e6)\n",
    "log_reg_0 = log_reg_0.fit(moa_features_train,moa_targets_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = log_reg_0.score(moa_features_validate,train_targets_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993002099370188"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = log_reg_0.predict(moa_features_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ones_0= np.count_nonzero(prediction, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_ones_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "linda = LinDA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(9, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "c:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=2, priors=None, shrinkage=None,\n",
       "                           solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linda.fit(train_features_b_dummies.iloc[:,1:10], train_targets_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap = Isomap(n_components = 10, n_neighbors = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-c078700c0f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miris_isomap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misomap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features_b_dummies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1492\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1493\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1494\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1495\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   2157\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2159\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m             \u001b[1;31m# if the dim was reduced, then pass a lower-dim the next time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2210\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   2178\u001b[0m         \u001b[0mslice_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_slice_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2180\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'iloc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, obj, axis, kind)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, slobj, axis, kind)\u001b[0m\n\u001b[0;32m   3160\u001b[0m         \"\"\"\n\u001b[0;32m   3161\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3162\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3163\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1310\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[0;32m   1311\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                                               fill_tuple=None))\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[0;32m   1232\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[1;32m-> 1234\u001b[1;33m                                        allow_fill=False, fill_value=fill_value)\n\u001b[0m\u001b[0;32m   1235\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ynche\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[0;32m   1649\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1650\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1651\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iris_isomap = isomap.fit_transform(train_features_b_dummies.iloc[:,1:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
